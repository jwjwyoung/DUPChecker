-----------0.1.0 vs 0.1.1-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.1.1 vs 0.1.2-----------
add: 6, delete: 1, change: 26, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------0.1.2 vs 0.1.3-----------
add: 1, delete: 0, change: 10, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.1.3 vs 0.18.0-----------
add: 147, delete: 90, change: 114, unhandled: 0 size_exceptions: 10 size_serialize: 0
-----------0.18.0 vs 0.18.1-----------
add: 2, delete: 0, change: 17, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------0.18.1 vs 0.19.0-----------
add: 51, delete: 25, change: 127, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------0.19.0 vs 0.19.1-----------
add: 4, delete: 0, change: 80, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.19.1 vs 0.19.1RC1-----------
add: 0, delete: 1, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.19.1RC1 vs 0.19.2-----------
add: 2, delete: 0, change: 26, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.19.2 vs 0.19.3RC1-----------
add: 2, delete: 0, change: 26, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.19.3RC1 vs 0.19.4RC1-----------
add: 0, delete: 0, change: 14, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.19.4RC1 vs 0.20.0-----------
add: 303, delete: 85, change: 184, unhandled: 0 size_exceptions: 13 size_serialize: 0
-----------0.20.0 vs 0.20.0-alpha-----------
add: 38, delete: 168, change: 159, unhandled: 0 size_exceptions: 9 size_serialize: 0
-----------0.20.0-alpha vs 0.20.0RC1-----------
add: 159, delete: 38, change: 146, unhandled: 0 size_exceptions: 6 size_serialize: 0
-----------0.20.0RC1 vs 0.20.0RC3-----------
add: 10, delete: 1, change: 55, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------0.20.0RC3 vs 0.20.1-----------
add: 14, delete: 1, change: 76, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.20.1 vs 0.20.1RC2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.1RC2 vs 0.20.2-----------
add: 0, delete: 0, change: 60, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.20.2 vs 0.20.3-----------
add: 78, delete: 0, change: 65, unhandled: 2 size_exceptions: 1 size_serialize: 0
-----------0.20.3 vs 0.20.3RC1-----------
add: 0, delete: 0, change: 17, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.3RC1 vs 0.20.3RC2-----------
add: 0, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.3RC2 vs 0.20.4-----------
add: 31, delete: 75, change: 174, unhandled: 2 size_exceptions: 11 size_serialize: 0
-----------0.20.4 vs 0.20.4RC1-----------
add: 0, delete: 1, change: 39, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.4RC1 vs 0.20.4RC3-----------
add: 0, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.4RC3 vs 0.20.4RC4-----------
add: 1, delete: 0, change: 23, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.4RC4 vs 0.20.4RC5-----------
add: 0, delete: 0, change: 5, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.4RC5 vs 0.20.5-----------
add: 2, delete: 21, change: 51, unhandled: 0 size_exceptions: 12 size_serialize: 0
-----------0.20.5 vs 0.20.5RC2-----------
add: 0, delete: 1, change: 9, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.5RC2 vs 0.20.5RC3-----------
add: 1, delete: 0, change: 6, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.5RC3 vs 0.20.5RC5-----------
add: 0, delete: 0, change: 6, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.5RC5 vs 0.20.6-----------
add: 2, delete: 0, change: 9, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.6 vs 0.20.6RC1-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.20.6RC1 vs 0.89.20100621-----------
add: 529, delete: 562, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100621 vs 0.89.20100621-0.89.20100621-rc1-----------
add: 0, delete: 0, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100621-0.89.20100621-rc1 vs 0.89.20100621-rc0-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100621-rc0 vs 0.89.20100621-rc1-----------
add: 0, delete: 0, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100621-rc1 vs 0.89.20100726-----------
add: 37, delete: 8, change: 83, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------0.89.20100726 vs 0.89.20100726RC2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100726RC2 vs 0.89.20100726rc1-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100726rc1 vs 0.89.20100830RC1-----------
add: 9, delete: 4, change: 51, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100830RC1 vs 0.89.20100830RC2-----------
add: 0, delete: 0, change: 8, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100830RC2 vs 0.89.20100924RC1-----------
add: 0, delete: 0, change: 32, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.89.20100924RC1 vs 0.90.0-----------
add: 811, delete: 71, change: 224, unhandled: 0 size_exceptions: 24 size_serialize: 0
-----------0.90.0 vs 0.90.0RC0-----------
add: 1, delete: 683, change: 88, unhandled: 0 size_exceptions: 10 size_serialize: 0
-----------0.90.0RC0 vs 0.90.0RC1-----------
add: 8, delete: 0, change: 59, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0RC1 vs 0.90.0RC2-----------
add: 631, delete: 1, change: 43, unhandled: 0 size_exceptions: 10 size_serialize: 0
-----------0.90.0RC2 vs 0.90.0RC3-----------
add: 3, delete: 630, change: 19, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0RC3 vs 0.90.0mvn-----------
add: 633, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0mvn vs 0.90.0mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0mvn2 vs 0.90.0mvn3-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0mvn3 vs 0.90.0mvn4-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0mvn4 vs 0.90.0mvn7-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0mvn7 vs 0.90.0mvn8-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.0mvn8 vs 0.90.1-----------
add: 4, delete: 38, change: 89, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------0.90.1 vs 0.90.1RC0-----------
add: 0, delete: 0, change: 5, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.1RC0 vs 0.90.1RC1-----------
add: 0, delete: 0, change: 5, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.1RC1 vs 0.90.2-----------
add: 3, delete: 0, change: 56, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------0.90.2 vs 0.90.2RC0-v2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.2RC0-v2 vs 0.90.2mvn-----------
add: 640, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.2mvn vs 0.90.2mvn-step2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.2mvn-step2 vs 0.90.2mvn-v2-----------
add: 0, delete: 640, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.2mvn-v2 vs 0.90.2mvn3-----------
add: 640, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.2mvn3 vs 0.90.3-----------
add: 1, delete: 640, change: 57, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------0.90.3 vs 0.90.3RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.3RC0 vs 0.90.3mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.3mvn vs 0.90.3mvnrelease-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.3mvnrelease vs 0.90.4-----------
add: 5, delete: 0, change: 65, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------0.90.4 vs 0.90.4.mvn-----------
add: 646, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.4.mvn vs 0.90.4.mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.4.mvn2 vs 0.90.4RC0-----------
add: 0, delete: 646, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.4RC0 vs 0.90.4RC1-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.4RC1 vs 0.90.5-----------
add: 25, delete: 0, change: 104, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------0.90.5 vs 0.90.5RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.5RC0 vs 0.90.5mvn-----------
add: 671, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.5mvn vs 0.90.5mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.5mvn2 vs 0.90.6-----------
add: 3, delete: 679, change: 49, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.6 vs 0.90.6RC0-----------
add: 8, delete: 2, change: 31, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.6RC0 vs 0.90.6RC5-----------
add: 2, delete: 8, change: 31, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.6RC5 vs 0.90.6rc0-----------
add: 8, delete: 2, change: 31, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.90.6rc0 vs 0.92.0-----------
add: 263, delete: 49, change: 385, unhandled: 0 size_exceptions: 63 size_serialize: 0
-----------0.92.0 vs 0.92.0RC1-----------
add: 0, delete: 2, change: 70, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.92.0RC1 vs 0.92.0RC2-----------
add: 1, delete: 0, change: 31, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0RC2 vs 0.92.0mvn-----------
add: 1, delete: 0, change: 44, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.92.0mvn vs 0.92.0mvn0-----------
add: 141, delete: 9, change: 786, unhandled: 0 size_exceptions: 10 size_serialize: 0
-----------0.92.0mvn0 vs 0.92.0mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn2 vs 0.92.0mvn3-----------
add: 9, delete: 141, change: 786, unhandled: 0 size_exceptions: 10 size_serialize: 0
-----------0.92.0mvn3 vs 0.92.0mvn4-----------
add: 886, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn4 vs 0.92.0mvn5-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn5 vs 0.92.0mvn6-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn6 vs 0.92.0mvn7-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn7 vs 0.92.0mvn10-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn10 vs 0.92.0mvn11-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn11 vs 0.92.0mvn12-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn12 vs 0.92.0mvn13-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn13 vs 0.92.0mvn20-----------
add: 0, delete: 886, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn20 vs 0.92.0mvn21-----------
add: 886, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn21 vs 0.92.0mvn30-----------
add: 0, delete: 886, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn30 vs 0.92.0mvn40-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn40 vs 0.92.0mvn50-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn50 vs 0.92.0mvn_release-----------
add: 886, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0mvn_release vs 0.92.0rc0-----------
add: 0, delete: 889, change: 96, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.92.0rc0 vs 0.92.0rc2-----------
add: 2, delete: 0, change: 66, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0rc2 vs 0.92.0rc3-----------
add: 1, delete: 0, change: 36, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.92.0rc3 vs 0.92.0rc4-----------
add: 0, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.0rc4 vs 0.92.1-----------
add: 7, delete: 4, change: 64, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------0.92.1 vs 0.92.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.1RC0 vs 0.92.1mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.1mvn vs 0.92.1mvn0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.1mvn0 vs 0.92.1mvn1-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.1mvn1 vs 0.92.1mvn2security-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.1mvn2security vs 0.92.1mvn3security-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.1mvn3security vs 0.92.2-----------
add: 30, delete: 0, change: 163, unhandled: 0 size_exceptions: 8 size_serialize: 0
-----------0.92.2 vs 0.92.2.st.mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.2.st.mvn vs 0.92.2.st.mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.2.st.mvn2 vs 0.92.2mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.2mvn vs 0.92.2mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.2mvn2 vs 0.92.2mvn3-----------
add: 1212, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.2mvn3 vs 0.92.2rc0-----------
add: 0, delete: 1212, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.2rc0 vs 0.92.2rc1-----------
add: 0, delete: 0, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.92.2rc1 vs 0.94.0-----------
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(version);

    BlockType.TRAILER.readAndCheck(inputStream);

    fileInfoOffset = inputStream.readLong();
    loadOnOpenDataOffset = inputStream.readLong();
    dataIndexCount = inputStream.readInt();

    if (version == 1) {
      inputStream.readLong(); // Read and skip metaIndexOffset.
    } else {
      uncompressedDataIndexSize = inputStream.readLong();
    }
    metaIndexCount = inputStream.readInt();

    totalUncompressedBytes = inputStream.readLong();
    entryCount = version == 1 ? inputStream.readInt() : inputStream.readLong();
    compressionCodec = Compression.Algorithm.values()[inputStream.readInt()];
    if (version > 1) {
      numDataIndexLevels = inputStream.readInt();
      firstDataBlockOffset = inputStream.readLong();
      lastDataBlockOffset = inputStream.readLong();
      comparatorClassName =
          Bytes.readStringFixedSize(inputStream, MAX_COMPARATOR_NAME_LENGTH);
    }

    expectVersion(inputStream.readInt());
  }

+++++++++++++++++++++++
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    BlockType.TRAILER.readAndCheck(inputStream);

    fileInfoOffset = inputStream.readLong();
    loadOnOpenDataOffset = inputStream.readLong();
    dataIndexCount = inputStream.readInt();

    if (majorVersion == 1) {
      inputStream.readLong(); // Read and skip metaIndexOffset.
    } else {
      uncompressedDataIndexSize = inputStream.readLong();
    }
    metaIndexCount = inputStream.readInt();

    totalUncompressedBytes = inputStream.readLong();
    entryCount = majorVersion == 1 ? inputStream.readInt() : inputStream.readLong();
    compressionCodec = Compression.Algorithm.values()[inputStream.readInt()];
    if (majorVersion > 1) {
      numDataIndexLevels = inputStream.readInt();
      firstDataBlockOffset = inputStream.readLong();
      lastDataBlockOffset = inputStream.readLong();
      comparatorClassName =
          Bytes.readStringFixedSize(inputStream, MAX_COMPARATOR_NAME_LENGTH);
    }

    int version = inputStream.readInt();
    expectMajorVersion(extractMajorVersion(version));
    expectMinorVersion(extractMinorVersion(version));
  }

  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(version);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutput baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    baosDos.writeLong(fileInfoOffset);
    baosDos.writeLong(loadOnOpenDataOffset);
    baosDos.writeInt(dataIndexCount);

    if (version == 1) {
      // This used to be metaIndexOffset, but it was not used in version 1.
      baosDos.writeLong(0);
    } else {
      baosDos.writeLong(uncompressedDataIndexSize);
    }

    baosDos.writeInt(metaIndexCount);
    baosDos.writeLong(totalUncompressedBytes);
    if (version == 1) {
      baosDos.writeInt((int) Math.min(Integer.MAX_VALUE, entryCount));
    } else {
      // This field is long from version 2 onwards.
      baosDos.writeLong(entryCount);
    }
    baosDos.writeInt(compressionCodec.ordinal());

    if (version > 1) {
      baosDos.writeInt(numDataIndexLevels);
      baosDos.writeLong(firstDataBlockOffset);
      baosDos.writeLong(lastDataBlockOffset);
      Bytes.writeStringFixedSize(baosDos, comparatorClassName,
          MAX_COMPARATOR_NAME_LENGTH);
    }
    baosDos.writeInt(version);

    outputStream.write(baos.toByteArray());
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @param version
   * @throws IOException
   */
+++++++++++++++++++++++
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutput baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    baosDos.writeLong(fileInfoOffset);
    baosDos.writeLong(loadOnOpenDataOffset);
    baosDos.writeInt(dataIndexCount);

    if (majorVersion == 1) {
      // This used to be metaIndexOffset, but it was not used in version 1.
      baosDos.writeLong(0);
    } else {
      baosDos.writeLong(uncompressedDataIndexSize);
    }

    baosDos.writeInt(metaIndexCount);
    baosDos.writeLong(totalUncompressedBytes);
    if (majorVersion == 1) {
      baosDos.writeInt((int) Math.min(Integer.MAX_VALUE, entryCount));
    } else {
      // This field is long from version 2 onwards.
      baosDos.writeLong(entryCount);
    }
    baosDos.writeInt(compressionCodec.ordinal());

    if (majorVersion > 1) {
      baosDos.writeInt(numDataIndexLevels);
      baosDos.writeLong(firstDataBlockOffset);
      baosDos.writeLong(lastDataBlockOffset);
      Bytes.writeStringFixedSize(baosDos, comparatorClassName,
          MAX_COMPARATOR_NAME_LENGTH);
    }

    // serialize the major and minor versions
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    outputStream.write(baos.toByteArray());
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @param version
   * @throws IOException
   */
add: 150, delete: 14, change: 517, unhandled: 0 size_exceptions: 10 size_serialize: 2
-----------0.94.0 vs 0.94.0RC0-----------
add: 6, delete: 13, change: 130, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------0.94.0RC0 vs 0.94.0RC1-----------
add: 5, delete: 6, change: 80, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------0.94.0RC1 vs 0.94.0RC2-----------
add: 2, delete: 0, change: 11, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.0RC2 vs 0.94.0RC3-----------
add: 6, delete: 0, change: 54, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------0.94.0RC3 vs 0.94.0mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.0mvn vs 0.94.0mvnrelease-----------
add: 1106, delete: 1055, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.0mvnrelease vs 0.94.0mvnreleased2-----------
add: 1055, delete: 1106, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.0mvnreleased2 vs 0.94.1-----------
add: 11, delete: 5, change: 162, unhandled: 0 size_exceptions: 17 size_serialize: 0
-----------0.94.1 vs 0.94.1RC0-----------
add: 1, delete: 0, change: 23, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.1RC0 vs 0.94.1RC1-----------
add: 0, delete: 1, change: 23, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.1RC1 vs 0.94.1mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.1mvn vs 0.94.1mvn_perform-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.1mvn_perform vs 0.94.1mvn_prepare-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.1mvn_prepare vs 0.94.2-----------
add: 18, delete: 1, change: 114, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------0.94.2 vs 0.94.2RC0-----------
add: 1, delete: 1, change: 27, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.2RC0 vs 0.94.2RC1-----------
add: 0, delete: 0, change: 8, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.2RC1 vs 0.94.2RC2-----------
add: 0, delete: 0, change: 5, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.2RC2 vs 0.94.2RC3-----------
add: 1, delete: 1, change: 16, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.2RC3 vs 0.94.2mvn-----------
add: 1078, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.2mvn vs 0.94.2mvnrelease-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.2mvnrelease vs 0.94.3-----------
add: 27, delete: 1082, change: 89, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.94.3 vs 0.94.3RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.3RC0 vs 0.94.3mvn-----------
add: 1101, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.3mvn vs 0.94.3mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.3mvn2 vs 0.94.3mvn_release-----------
add: 0, delete: 1101, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.3mvn_release vs 0.94.4-----------
add: 34, delete: 0, change: 157, unhandled: 0 size_exceptions: 12 size_serialize: 0
-----------0.94.4 vs 0.94.4RC0-----------
add: 0, delete: 4, change: 35, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.94.4RC0 vs 0.94.4RC1-----------
add: 4, delete: 0, change: 35, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.94.4RC1 vs 0.94.4mvn-----------
add: 2270, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.4mvn vs 0.94.4mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.4mvn2 vs 0.94.5-----------
add: 20, delete: 2272, change: 129, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.5 vs 0.94.5RC0-----------
add: 0, delete: 1, change: 18, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.5RC0 vs 0.94.5RC1-----------
add: 1, delete: 0, change: 18, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.5RC1 vs 0.94.5mvn-----------
add: 1153, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.5mvn vs 0.94.5mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.5mvn2 vs 0.94.6-----------
add: 99, delete: 1154, change: 111, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------0.94.6 vs 0.94.6.1-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6.1 vs 0.94.6.1mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6.1mvn vs 0.94.6.1mvn-release2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6.1mvn-release2 vs 0.94.6RC0-----------
add: 0, delete: 3, change: 21, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6RC0 vs 0.94.6RC1-----------
add: 1, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6RC1 vs 0.94.6RC2-----------
add: 2, delete: 0, change: 18, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6RC2 vs 0.94.6mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6mvn vs 0.94.6mvn-release-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.6mvn-release vs 0.94.7-----------
add: 21, delete: 2, change: 146, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------0.94.7 vs 0.94.7RC0-----------
add: 1, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.7RC0 vs 0.94.7RC1-----------
add: 0, delete: 1, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.7RC1 vs 0.94.7mvn-----------
add: 1270, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.7mvn vs 0.94.7mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.7mvn2 vs 0.94.8-----------
add: 6, delete: 1271, change: 77, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.94.8 vs 0.94.8RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.8RC0 vs 0.94.9-----------
add: 11, delete: 0, change: 46, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.9 vs 0.94.9RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.9RC0 vs 0.94.9mvn-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.9mvn vs 0.94.9mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.9mvn2 vs 0.94.10-----------
add: 4, delete: 0, change: 72, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------0.94.10 vs 0.94.10RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.10RC0 vs 0.94.10mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.10mvn vs 0.94.10mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.10mvn2 vs 0.94.11-----------
add: 4, delete: 0, change: 94, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.94.11 vs 0.94.11RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.11RC0 vs 0.94.11mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.11mvn vs 0.94.11mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.11mvn2 vs 0.94.12-----------
add: 4, delete: 0, change: 65, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------0.94.12 vs 0.94.12RC0-----------
add: 0, delete: 2, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.12RC0 vs 0.94.12RC1-----------
add: 1, delete: 0, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.12RC1 vs 0.94.12RC2-----------
add: 1, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.12RC2 vs 0.94.12mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.12mvn vs 0.94.12mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.12mvn2 vs 0.94.13-----------
add: 7, delete: 0, change: 74, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.13 vs 0.94.13RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.13RC0 vs 0.94.13mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.13mvn vs 0.94.13mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.13mvn2 vs 0.94.14-----------
add: 7, delete: 0, change: 32, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.14 vs 0.94.14RC0-----------
add: 0, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.14RC0 vs 0.94.14RC1-----------
add: 0, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.14RC1 vs 0.94.14mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.14mvn vs 0.94.14mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.14mvn2 vs 0.94.15-----------
add: 3, delete: 0, change: 34, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.15 vs 0.94.15-junit-4.11-----------
add: 0, delete: 0, change: 17, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.15-junit-4.11 vs 0.94.15RC0-----------
add: 0, delete: 0, change: 17, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.15RC0 vs 0.94.15mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.15mvn vs 0.94.15mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.15mvn2 vs 0.94.16-----------
add: 0, delete: 1, change: 28, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.16 vs 0.94.16RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.16RC0 vs 0.94.16mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.16mvn vs 0.94.16mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.16mvn2 vs 0.94.17-----------
add: 2, delete: 1, change: 50, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.94.17 vs 0.94.17RC0-----------
add: 0, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.17RC0 vs 0.94.17RC1-----------
add: 0, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.17RC1 vs 0.94.17mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.17mvn vs 0.94.17mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.17mvn2 vs 0.94.18-----------
add: 3, delete: 0, change: 38, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.94.18 vs 0.94.18RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.18RC0 vs 0.94.18mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.18mvn vs 0.94.18mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.18mvn2 vs 0.94.19-----------
add: 2, delete: 0, change: 32, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.19 vs 0.94.19RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.19RC0 vs 0.94.19mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.19mvn vs 0.94.19mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.19mvn2 vs 0.94.20-----------
add: 1, delete: 0, change: 22, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.20 vs 0.94.20RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.20RC0 vs 0.94.20mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.20mvn2 vs 0.94.21-----------
add: 1, delete: 0, change: 20, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.21 vs 0.94.21RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.21RC0 vs 0.94.22-----------
add: 0, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.22 vs 0.94.22RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.22RC0 vs 0.94.23-----------
add: 2, delete: 0, change: 10, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------0.94.23 vs 0.94.23RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.23RC0 vs 0.94.24-----------
add: 4, delete: 0, change: 18, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.24 vs 0.94.24RC0-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.24RC0 vs 0.94.24RC1-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.24RC1 vs 0.94.24RC2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.24RC2 vs 0.94.25-----------
add: 0, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.25 vs 0.94.25RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.25RC0 vs 0.94.26-----------
add: 0, delete: 0, change: 34, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.26 vs 0.94.26RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.26RC0 vs 0.94.27-----------
add: 0, delete: 0, change: 12, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.27 vs 0.94.27RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.27RC0 vs 0.94.28RC0-----------
add: 1, delete: 2, change: 16, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.94.28RC0 vs 0.95.0-----------
add: 1653, delete: 1327, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.0 vs 0.95.0RC0-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.0RC0 vs 0.95.0RC1-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.0RC1 vs 0.95.0mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.0mvn vs 0.95.0mvn-release-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.0mvn-release vs 0.95.0mvnrelease-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.0mvnrelease vs 0.95.1-----------
add: 95, delete: 50, change: 447, unhandled: 0 size_exceptions: 21 size_serialize: 0
-----------0.95.1 vs 0.95.1-hadoop1.mvnlabeling2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.1-hadoop1.mvnlabeling2 vs 0.95.1-hadoop2.mvn.label4-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.1-hadoop2.mvn.label4 vs 0.95.1RC0-----------
add: 0, delete: 2, change: 37, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.95.1RC0 vs 0.95.1RC1-----------
add: 2, delete: 0, change: 37, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.95.1RC1 vs 0.95.1mvn-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.1mvn vs 0.95.1mvn2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.95.1mvn2 vs 0.95.2-----------
  void deserializeFromWritable(DataInput input) throws IOException {
    fileInfoOffset = input.readLong();
    loadOnOpenDataOffset = input.readLong();
    dataIndexCount = input.readInt();
    if (majorVersion == 1) {
      input.readLong(); // Read and skip metaIndexOffset.
    } else {
      uncompressedDataIndexSize = input.readLong();
    }
    metaIndexCount = input.readInt();

    totalUncompressedBytes = input.readLong();
    entryCount = majorVersion == 1 ? input.readInt() : input.readLong();
    compressionCodec = Compression.Algorithm.values()[input.readInt()];
    if (majorVersion > 1) {
      numDataIndexLevels = input.readInt();
      firstDataBlockOffset = input.readLong();
      lastDataBlockOffset = input.readLong();
      setComparatorClass(getComparatorClass(Bytes.readStringFixedSize(input,
        MAX_COMPARATOR_NAME_LENGTH)));
    }
  }
  
+++++++++++++++++++++++
  void deserializeFromWritable(DataInput input) throws IOException {
    fileInfoOffset = input.readLong();
    loadOnOpenDataOffset = input.readLong();
    dataIndexCount = input.readInt();
    uncompressedDataIndexSize = input.readLong();
    metaIndexCount = input.readInt();

    totalUncompressedBytes = input.readLong();
    entryCount = input.readLong();
    compressionCodec = Compression.Algorithm.values()[input.readInt()];
    numDataIndexLevels = input.readInt();
    firstDataBlockOffset = input.readLong();
    lastDataBlockOffset = input.readLong();
    setComparatorClass(getComparatorClass(Bytes.readStringFixedSize(input,
        MAX_COMPARATOR_NAME_LENGTH)));
  }
  
  void serializeAsWritable(DataOutputStream output) throws IOException {
    output.writeLong(fileInfoOffset);
    output.writeLong(loadOnOpenDataOffset);
    output.writeInt(dataIndexCount);

    if (majorVersion == 1) {
      // This used to be metaIndexOffset, but it was not used in version 1.
      output.writeLong(0);
    } else {
      output.writeLong(uncompressedDataIndexSize);
    }

    output.writeInt(metaIndexCount);
    output.writeLong(totalUncompressedBytes);
    if (majorVersion == 1) {
      output.writeInt((int) Math.min(Integer.MAX_VALUE, entryCount));
    } else {
      // This field is long from version 2 onwards.
      output.writeLong(entryCount);
    }
    output.writeInt(compressionCodec.ordinal());

    if (majorVersion > 1) {
      output.writeInt(numDataIndexLevels);
      output.writeLong(firstDataBlockOffset);
      output.writeLong(lastDataBlockOffset);
      Bytes.writeStringFixedSize(output, comparatorClassName, MAX_COMPARATOR_NAME_LENGTH);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsWritable(DataOutputStream output) throws IOException {
    output.writeLong(fileInfoOffset);
    output.writeLong(loadOnOpenDataOffset);
    output.writeInt(dataIndexCount);

    output.writeLong(uncompressedDataIndexSize);

    output.writeInt(metaIndexCount);
    output.writeLong(totalUncompressedBytes);
    output.writeLong(entryCount);
    output.writeInt(compressionCodec.ordinal());

    output.writeInt(numDataIndexLevels);
    output.writeLong(firstDataBlockOffset);
    output.writeLong(lastDataBlockOffset);
    Bytes.writeStringFixedSize(output, comparatorClassName, MAX_COMPARATOR_NAME_LENGTH);
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
add: 195, delete: 79, change: 742, unhandled: 0 size_exceptions: 18 size_serialize: 2
-----------0.95.2 vs 0.96.0RC0-----------
add: 32, delete: 3, change: 423, unhandled: 0 size_exceptions: 31 size_serialize: 0
-----------0.96.0RC0 vs 0.96.0RC1-----------
add: 10, delete: 3, change: 437, unhandled: 0 size_exceptions: 6 size_serialize: 0
-----------0.96.0RC1 vs 0.96.0RC3-----------
add: 54, delete: 48, change: 127, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.0RC3 vs 0.96.0RC4-----------
add: 5, delete: 7, change: 161, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.96.0RC4 vs 0.96.0RC5-----------
add: 1, delete: 2, change: 23, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.0RC5 vs 0.96.0rc2-----------
add: 57, delete: 55, change: 260, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.96.0rc2 vs 0.96.1-----------
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal())
      .build().writeDelimitedTo(baos);
    output.write(baos.toByteArray());
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Write trailer data as writable
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal())
      .build()
      // We need the extra copy unfortunately to determine the final size of
      // the delimited output, see use of baos.size() below.
      .writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Write trailer data as writable
   * @param outputStream
   * @throws IOException
   */
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      serializeAsPB(baosDos);
    } else {
      serializeAsWritable(baosDos);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    outputStream.write(baos.toByteArray());
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      serializeAsPB(baosDos);
    } else {
      serializeAsWritable(baosDos);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    baos.writeTo(outputStream);
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
  public Deserializer<Result> getDeserializer(Class<Result> c) {
    return new ResultDeserializer();
  }

  @Override
+++++++++++++++++++++++
  public Deserializer<Result> getDeserializer(Class<Result> c) {
    // check input format version
    Configuration conf = getConf();
    if (conf != null) {
      String inputVersion = conf.get(IMPORT_FORMAT_VER);
      if (inputVersion != null && inputVersion.equals("0.94")) {
        LOG.info("Load exported file using deserializer for HBase 0.94 format");
        return new Result94Deserializer();
      }
    }

    return new ResultDeserializer();
  }

  @Override
add: 75, delete: 60, change: 499, unhandled: 0 size_exceptions: 5 size_serialize: 3
-----------0.96.1 vs 0.96.1.1-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.1.1 vs 0.96.1.1rc0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.1.1rc0 vs 0.96.1RC0-----------
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal())
      .build()
      // We need the extra copy unfortunately to determine the final size of
      // the delimited output, see use of baos.size() below.
      .writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Write trailer data as writable
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal())
      .build().writeDelimitedTo(baos);
    output.write(baos.toByteArray());
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Write trailer data as writable
   * @param outputStream
   * @throws IOException
   */
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      serializeAsPB(baosDos);
    } else {
      serializeAsWritable(baosDos);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    baos.writeTo(outputStream);
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      serializeAsPB(baosDos);
    } else {
      serializeAsWritable(baosDos);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    outputStream.write(baos.toByteArray());
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
add: 0, delete: 0, change: 51, unhandled: 0 size_exceptions: 0 size_serialize: 2
-----------0.96.1RC0 vs 0.96.1RC2-----------
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal())
      .build().writeDelimitedTo(baos);
    output.write(baos.toByteArray());
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Write trailer data as writable
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal())
      .build()
      // We need the extra copy unfortunately to determine the final size of
      // the delimited output, see use of baos.size() below.
      .writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Write trailer data as writable
   * @param outputStream
   * @throws IOException
   */
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      serializeAsPB(baosDos);
    } else {
      serializeAsWritable(baosDos);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    outputStream.write(baos.toByteArray());
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      serializeAsPB(baosDos);
    } else {
      serializeAsWritable(baosDos);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    baos.writeTo(outputStream);
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
add: 0, delete: 0, change: 50, unhandled: 0 size_exceptions: 0 size_serialize: 2
-----------0.96.1RC2 vs 0.96.1new-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.1new vs 0.96.2-----------
add: 24, delete: 3, change: 231, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------0.96.2 vs 0.96.2-RC2-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.2-RC2 vs 0.96.2RC0-----------
add: 0, delete: 0, change: 6, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.2RC0 vs 0.96.2RC1-----------
add: 0, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.2RC1 vs 0.96.2RC2-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.96.2RC2 vs 0.98.0-----------
  void deserializeFromPB(DataInputStream inputStream) throws IOException {
    // read PB and skip padding
    int start = inputStream.available();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder();
    builder.mergeDelimitedFrom(inputStream);
    int size = start - inputStream.available();
    inputStream.skip(getTrailerSize() - NOT_PB_SIZE - size);

    // process the PB
    if (builder.hasFileInfoOffset()) {
      fileInfoOffset = builder.getFileInfoOffset();
    }
    if (builder.hasLoadOnOpenDataOffset()) {
      loadOnOpenDataOffset = builder.getLoadOnOpenDataOffset();
    }
    if (builder.hasUncompressedDataIndexSize()) {
      uncompressedDataIndexSize = builder.getUncompressedDataIndexSize();
    }
    if (builder.hasTotalUncompressedBytes()) {
      totalUncompressedBytes = builder.getTotalUncompressedBytes();
    }
    if (builder.hasDataIndexCount()) {
      dataIndexCount = builder.getDataIndexCount();
    }
    if (builder.hasMetaIndexCount()) {
      metaIndexCount = builder.getMetaIndexCount();
    }
    if (builder.hasEntryCount()) {
      entryCount = builder.getEntryCount();
    }
    if (builder.hasNumDataIndexLevels()) {
      numDataIndexLevels = builder.getNumDataIndexLevels();
    }
    if (builder.hasFirstDataBlockOffset()) {
      firstDataBlockOffset = builder.getFirstDataBlockOffset();
    }
    if (builder.hasLastDataBlockOffset()) {
      lastDataBlockOffset = builder.getLastDataBlockOffset();
    }
    if (builder.hasComparatorClassName()) {
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      setComparatorClass(getComparatorClass(builder.getComparatorClassName()));
    }
    if (builder.hasCompressionCodec()) {
      compressionCodec = Compression.Algorithm.values()[builder.getCompressionCodec()];
    } else {
      compressionCodec = Compression.Algorithm.NONE;
    }
  }

  /**
   * Deserialize the file trailer as writable data
   * @param input
   * @throws IOException
   */
+++++++++++++++++++++++
  void deserializeFromPB(DataInputStream inputStream) throws IOException {
    // read PB and skip padding
    int start = inputStream.available();
    HFileProtos.FileTrailerProto trailerProto =
        HFileProtos.FileTrailerProto.PARSER.parseDelimitedFrom(inputStream);
    int size = start - inputStream.available();
    inputStream.skip(getTrailerSize() - NOT_PB_SIZE - size);

    // process the PB
    if (trailerProto.hasFileInfoOffset()) {
      fileInfoOffset = trailerProto.getFileInfoOffset();
    }
    if (trailerProto.hasLoadOnOpenDataOffset()) {
      loadOnOpenDataOffset = trailerProto.getLoadOnOpenDataOffset();
    }
    if (trailerProto.hasUncompressedDataIndexSize()) {
      uncompressedDataIndexSize = trailerProto.getUncompressedDataIndexSize();
    }
    if (trailerProto.hasTotalUncompressedBytes()) {
      totalUncompressedBytes = trailerProto.getTotalUncompressedBytes();
    }
    if (trailerProto.hasDataIndexCount()) {
      dataIndexCount = trailerProto.getDataIndexCount();
    }
    if (trailerProto.hasMetaIndexCount()) {
      metaIndexCount = trailerProto.getMetaIndexCount();
    }
    if (trailerProto.hasEntryCount()) {
      entryCount = trailerProto.getEntryCount();
    }
    if (trailerProto.hasNumDataIndexLevels()) {
      numDataIndexLevels = trailerProto.getNumDataIndexLevels();
    }
    if (trailerProto.hasFirstDataBlockOffset()) {
      firstDataBlockOffset = trailerProto.getFirstDataBlockOffset();
    }
    if (trailerProto.hasLastDataBlockOffset()) {
      lastDataBlockOffset = trailerProto.getLastDataBlockOffset();
    }
    if (trailerProto.hasComparatorClassName()) {
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      setComparatorClass(getComparatorClass(trailerProto.getComparatorClassName()));
    }
    if (trailerProto.hasCompressionCodec()) {
      compressionCodec = Compression.Algorithm.values()[trailerProto.getCompressionCodec()];
    } else {
      compressionCodec = Compression.Algorithm.NONE;
    }
    if (trailerProto.hasEncryptionKey()) {
      encryptionKey = trailerProto.getEncryptionKey().toByteArray();
    }
  }

  /**
   * Deserialize the file trailer as writable data
   * @param input
   * @throws IOException
   */
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    BlockType.TRAILER.readAndCheck(inputStream);

    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      deserializeFromPB(inputStream);
    } else {
      deserializeFromWritable(inputStream);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    int version = inputStream.readInt();
    expectMajorVersion(extractMajorVersion(version));
    expectMinorVersion(extractMinorVersion(version));
  }

  /**
   * Deserialize the file trailer as protobuf
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    BlockType.TRAILER.readAndCheck(inputStream);

    if (majorVersion > 2
        || (majorVersion == 2 && minorVersion >= HFileReaderV2.PBUF_TRAILER_MINOR_VERSION)) {
      deserializeFromPB(inputStream);
    } else {
      deserializeFromWritable(inputStream);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    int version = inputStream.readInt();
    expectMajorVersion(extractMajorVersion(version));
    expectMinorVersion(extractMinorVersion(version));
  }

  /**
   * Deserialize the file trailer as protobuf
   * @param inputStream
   * @throws IOException
   */
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal())
      .build()
      // We need the extra copy unfortunately to determine the final size of
      // the delimited output, see use of baos.size() below.
      .writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Write trailer data as writable
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(HBaseZeroCopyByteString.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    if (majorVersion > 2 || (majorVersion == 2 && minorVersion >= PBUF_TRAILER_MINOR_VERSION)) {
      serializeAsPB(baosDos);
    } else {
      serializeAsWritable(baosDos);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    baos.writeTo(outputStream);
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serialize(DataOutputStream outputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream baosDos = new DataOutputStream(baos);

    BlockType.TRAILER.write(baosDos);
    serializeAsPB(baosDos);

    // The last 4 bytes of the file encode the major and minor version universally
    baosDos.writeInt(materializeVersion(majorVersion, minorVersion));

    baos.writeTo(outputStream);
  }

  /**
   * Write trailer data as protobuf
   * @param outputStream
   * @throws IOException
   */
add: 183, delete: 17, change: 463, unhandled: 0 size_exceptions: 15 size_serialize: 4
-----------0.98.0 vs 0.98.0RC0-----------
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(HBaseZeroCopyByteString.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(ZeroCopyLiteralByteString.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
add: 1, delete: 5, change: 109, unhandled: 0 size_exceptions: 2 size_serialize: 1
-----------0.98.0RC0 vs 0.98.0RC1-----------
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(ZeroCopyLiteralByteString.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(HBaseZeroCopyByteString.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
add: 1, delete: 1, change: 67, unhandled: 0 size_exceptions: 2 size_serialize: 1
-----------0.98.0RC1 vs 0.98.0RC2-----------
add: 4, delete: 0, change: 49, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.0RC2 vs 0.98.1-----------
add: 31, delete: 1, change: 211, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------0.98.1 vs 0.98.1RC0-----------
add: 0, delete: 11, change: 33, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.1RC0 vs 0.98.1RC1-----------
add: 9, delete: 0, change: 20, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.1RC1 vs 0.98.1RC2-----------
add: 2, delete: 0, change: 8, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.1RC2 vs 0.98.1RC3-----------
add: 0, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.1RC3 vs 0.98.2-----------
add: 13, delete: 0, change: 86, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.2 vs 0.98.2RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.2RC0 vs 0.98.3-----------
add: 18, delete: 0, change: 125, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.3 vs 0.98.3RC0-----------
add: 0, delete: 4, change: 32, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.3RC0 vs 0.98.3RC1-----------
add: 1, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.3RC1 vs 0.98.3RC2-----------
add: 3, delete: 0, change: 23, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.3RC2 vs 0.98.4-----------
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(HBaseZeroCopyByteString.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(ByteStringer.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
add: 18, delete: 6, change: 249, unhandled: 0 size_exceptions: 5 size_serialize: 1
-----------0.98.4 vs 0.98.4RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.4RC0 vs 0.98.5-----------
add: 3, delete: 1, change: 103, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.5 vs 0.98.5RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.5RC0 vs 0.98.6-----------
add: 29, delete: 15, change: 185, unhandled: 0 size_exceptions: 8 size_serialize: 0
-----------0.98.6 vs 0.98.6.1-----------
add: 0, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.6.1 vs 0.98.6.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.6.1RC0 vs 0.98.6RC0-----------
add: 2, delete: 7, change: 41, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.6RC0 vs 0.98.6RC1-----------
add: 6, delete: 2, change: 35, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.6RC1 vs 0.98.6RC2-----------
add: 1, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.6RC2 vs 0.98.7-----------
add: 17, delete: 5, change: 1169, unhandled: 0 size_exceptions: 9 size_serialize: 0
-----------0.98.7 vs 0.98.7RC0-----------
add: 0, delete: 0, change: 6, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.7RC0 vs 0.98.7RC1-----------
add: 0, delete: 0, change: 6, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.7RC1 vs 0.98.8-----------
add: 121, delete: 103, change: 202, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.98.8 vs 0.98.8RC0-----------
add: 4, delete: 5, change: 16, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.8RC0 vs 0.98.8RC1-----------
add: 5, delete: 4, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.8RC1 vs 0.98.8RC2-----------
add: 0, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.8RC2 vs 0.98.9-----------
add: 30, delete: 6, change: 728, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.98.9 vs 0.98.9RC0-----------
add: 1, delete: 1, change: 31, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.9RC0 vs 0.98.9RC1-----------
add: 1, delete: 1, change: 31, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.9RC1 vs 0.98.10-----------
add: 31, delete: 0, change: 132, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.98.10 vs 0.98.10.1-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.10.1 vs 0.98.10.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.10.1RC0 vs 0.98.10RC0-----------
add: 0, delete: 0, change: 18, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.10RC0 vs 0.98.10RC1-----------
add: 0, delete: 0, change: 16, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.10RC1 vs 0.98.10RC2-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.10RC2 vs 0.98.11-----------
add: 13, delete: 1, change: 149, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------0.98.11 vs 0.98.11RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.11RC0 vs 0.98.12-----------
add: 12, delete: 1, change: 87, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.12 vs 0.98.12.1-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.12.1 vs 0.98.12.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.12.1RC0 vs 0.98.12RC0-----------
add: 1, delete: 8, change: 55, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.12RC0 vs 0.98.12RC1-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.12RC1 vs 0.98.12RC2-----------
add: 6, delete: 0, change: 29, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.12RC2 vs 0.98.12RC3-----------
add: 2, delete: 1, change: 34, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.12RC3 vs 0.98.13-----------
add: 15, delete: 0, change: 142, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.13 vs 0.98.13RC0-----------
add: 0, delete: 5, change: 28, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.13RC0 vs 0.98.13RC1-----------
add: 4, delete: 0, change: 22, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.13RC1 vs 0.98.13RC2-----------
add: 1, delete: 0, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.13RC2 vs 0.98.14-----------
add: 20, delete: 0, change: 193, unhandled: 0 size_exceptions: 7 size_serialize: 0
-----------0.98.14 vs 0.98.14RC0-----------
add: 0, delete: 0, change: 12, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.14RC0 vs 0.98.14RC1-----------
add: 0, delete: 0, change: 12, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.14RC1 vs 0.98.15-----------
add: 20, delete: 1, change: 128, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.98.15 vs 0.98.15RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.15RC0 vs 0.98.16-----------
add: 5, delete: 4, change: 112, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.16 vs 0.98.16.1-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.16.1 vs 0.98.16.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.16.1RC0 vs 0.98.16RC0-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.16RC0 vs 0.98.17RC0-----------
add: 33, delete: 2, change: 143, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.98.17RC0 vs 0.98.18RC0-----------
add: 9, delete: 0, change: 96, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.18RC0 vs 0.98.19RC0-----------
add: 24, delete: 3, change: 139, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.98.19RC0 vs 0.98.20RC0-----------
add: 8, delete: 5, change: 126, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.20RC0 vs 0.98.21RC0-----------
add: 9, delete: 0, change: 108, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------0.98.21RC0 vs 0.98.21RC1-----------
add: 0, delete: 1, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.21RC1 vs 0.98.22RC0-----------
add: 1, delete: 2, change: 37, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.22RC0 vs 0.98.23RC0-----------
add: 3, delete: 0, change: 24, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.23RC0 vs 0.98.24RC0-----------
add: 7, delete: 0, change: 73, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.98.24RC0 vs 0.99.0-----------
  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HFileOutputFormat.configureDataBlockEncoding(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HFileOutputFormat.configureDataBlockEncoding(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat.configureBlockSize(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat.configureBlockSize(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat.configureCompression(table, conf);

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat.configureCompression(table, conf);

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat.configureBloomType(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat.configureBloomType(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HFileOutputFormat2.configureDataBlockEncoding(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat2
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HFileOutputFormat2.configureDataBlockEncoding(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat2
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat2.configureBlockSize(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat2
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat2.configureBlockSize(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat2
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat2.configureCompression(table, conf);

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat2
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat2.configureCompression(table, conf);

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat2
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      HTable table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat2.configureBloomType(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat2
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat2.configureBloomType(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat2
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

add: 282, delete: 417, change: 1802, unhandled: 0 size_exceptions: 92 size_serialize: 8
-----------0.99.0 vs 0.99.0RC0-----------
add: 0, delete: 3, change: 60, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.99.0RC0 vs 0.99.0RC1-----------
add: 3, delete: 0, change: 60, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------0.99.0RC1 vs 0.99.1-----------
add: 130, delete: 114, change: 1320, unhandled: 0 size_exceptions: 8 size_serialize: 0
-----------0.99.1 vs 0.99.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.99.1RC0 vs 0.99.2-----------
add: 80, delete: 30, change: 713, unhandled: 0 size_exceptions: 20 size_serialize: 0
-----------0.99.2 vs 0.99.2RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------0.99.2RC0 vs 1.0.0-----------
add: 62, delete: 6, change: 935, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------1.0.0 vs 1.0.0RC0-----------
add: 1, delete: 32, change: 279, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------1.0.0RC0 vs 1.0.0RC1-----------
add: 25, delete: 0, change: 197, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------1.0.0RC1 vs 1.0.0RC2-----------
add: 0, delete: 0, change: 14, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.0.0RC2 vs 1.0.0RC3-----------
add: 1, delete: 0, change: 15, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.0.0RC3 vs 1.0.0RC4-----------
add: 1, delete: 0, change: 30, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.0.0RC4 vs 1.0.0RC5-----------
add: 5, delete: 1, change: 65, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------1.0.0RC5 vs 1.0.1-----------
add: 13, delete: 0, change: 158, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------1.0.1 vs 1.0.1.1-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.0.1.1 vs 1.0.1.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.0.1.1RC0 vs 1.0.1RC0-----------
add: 0, delete: 3, change: 34, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.0.1RC0 vs 1.0.1RC1-----------
add: 2, delete: 0, change: 18, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.0.1RC1 vs 1.0.1RC2-----------
add: 1, delete: 0, change: 17, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.0.1RC2 vs 1.0.2-----------
add: 23, delete: 1, change: 255, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------1.0.2 vs 1.0.2RC0-----------
add: 0, delete: 9, change: 110, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------1.0.2RC0 vs 1.0.2RC1-----------
add: 5, delete: 0, change: 95, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------1.0.2RC1 vs 1.0.2RC2-----------
add: 4, delete: 0, change: 19, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.0.2RC2 vs 1.0.3RC0-----------
add: 9, delete: 5, change: 159, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.0.3RC0 vs 1.0.3RC1-----------
add: 24, delete: 0, change: 67, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.0.3RC1 vs 1.1.0-----------
  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HFileOutputFormat2.configureDataBlockEncoding(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat2
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HTableDescriptor tableDescriptor = table.getTableDescriptor();
      HFileOutputFormat2.configureDataBlockEncoding(tableDescriptor, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat2
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat2.configureBlockSize(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat2
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat2.configureBlockSize(table.getTableDescriptor(), conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat2
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat2.configureCompression(table, conf);

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat2
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat2.configureCompression(conf, table.getTableDescriptor());

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat2
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat2.configureBloomType(table, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat2
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat2.configureBloomType(table.getTableDescriptor(), conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat2
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

add: 174, delete: 53, change: 713, unhandled: 0 size_exceptions: 24 size_serialize: 4
-----------1.1.0 vs 1.1.0-SNAPSHOT-testing-----------
add: 0, delete: 0, change: 16, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.0-SNAPSHOT-testing vs 1.1.0.1-----------
add: 0, delete: 0, change: 17, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.0.1 vs 1.1.0.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.0.1RC0 vs 1.1.0RC0-----------
add: 0, delete: 0, change: 17, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.0RC0 vs 1.1.0RC1-----------
add: 0, delete: 0, change: 14, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.0RC1 vs 1.1.0RC2-----------
add: 0, delete: 0, change: 2, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.0RC2 vs 1.1.1-----------
add: 20, delete: 0, change: 181, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.1 vs 1.1.1RC0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.1RC0 vs 1.1.2-----------
add: 5, delete: 0, change: 159, unhandled: 0 size_exceptions: 6 size_serialize: 0
-----------1.1.2 vs 1.1.2RC0-----------
add: 0, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.2RC0 vs 1.1.2RC1-----------
add: 0, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.2RC1 vs 1.1.2RC2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.2RC2 vs 1.1.3RC0-----------
add: 17, delete: 6, change: 196, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.1.3RC0 vs 1.1.3RC1-----------
add: 30, delete: 1, change: 140, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.1.3RC1 vs 1.1.4RC0-----------
add: 4, delete: 1, change: 74, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.4RC0 vs 1.1.5RC0-----------
add: 6, delete: 1, change: 92, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.5RC0 vs 1.1.6RC0-----------
add: 3, delete: 5, change: 69, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.1.6RC0 vs 1.1.6RC1-----------
add: 1, delete: 0, change: 36, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.1.6RC1 vs 1.1.6RC2-----------
add: 1, delete: 1, change: 21, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.1.6RC2 vs 1.1.7RC0-----------
add: 6, delete: 1, change: 41, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.1.7RC0 vs 1.1.7RC1-----------
add: 0, delete: 0, change: 19, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.7RC1 vs 1.1.8RC0-----------
add: 6, delete: 0, change: 75, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.1.8RC0 vs 1.1.9RC0-----------
add: 3, delete: 0, change: 47, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------1.1.9RC0 vs 1.1.10RC0-----------
add: 2, delete: 0, change: 11, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.10RC0 vs 1.1.11RC0-----------
add: 5, delete: 0, change: 24, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.11RC0 vs 1.1.12RC0-----------
add: 0, delete: 0, change: 19, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.12RC0 vs 1.1.13RC0-----------
add: 3, delete: 0, change: 14, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.1.13RC0 vs 1.2.0RC0-----------
add: 99, delete: 70, change: 994, unhandled: 0 size_exceptions: 23 size_serialize: 0
-----------1.2.0RC0 vs 1.2.0RC1-----------
add: 16, delete: 9, change: 181, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.0RC1 vs 1.2.0RC2-----------
add: 1, delete: 1, change: 15, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.0RC2 vs 1.2.0RC3-----------
add: 0, delete: 0, change: 28, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.0RC3 vs 1.2.0RC4-----------
add: 0, delete: 0, change: 11, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.0RC4 vs 1.2.1RC0-----------
add: 7, delete: 1, change: 81, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.1RC0 vs 1.2.1RC1-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.1RC1 vs 1.2.2RC0-----------
add: 9, delete: 5, change: 115, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.2.2RC0 vs 1.2.2RC1-----------
add: 0, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.2RC1 vs 1.2.2RC2-----------
add: 0, delete: 0, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.2RC2 vs 1.2.3RC0-----------
add: 2, delete: 1, change: 75, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------1.2.3RC0 vs 1.2.4RC0-----------
add: 7, delete: 1, change: 69, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.2.4RC0 vs 1.2.4RC1-----------
add: 4, delete: 0, change: 31, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.2.4RC1 vs 1.2.5RC0-----------
add: 7, delete: 0, change: 96, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.2.5RC0 vs 1.2.6.1RC0-----------
add: 5, delete: 0, change: 37, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.6.1RC0 vs 1.2.6RC0-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.6RC0 vs 1.2.7RC0-----------
add: 15, delete: 2, change: 225, unhandled: 0 size_exceptions: 6 size_serialize: 0
-----------1.2.7RC0 vs 1.2.8RC0-----------
add: 1, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.8RC0 vs 1.2.9RC0-----------
add: 0, delete: 0, change: 11, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.9RC0 vs 1.2.10RC0-----------
add: 5, delete: 0, change: 25, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.2.10RC0 vs 1.2.11RC0-----------
add: 1, delete: 0, change: 6, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.2.11RC0 vs 1.2.12RC0-----------
add: 3, delete: 0, change: 1, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.2.12RC0 vs 1.3.0RC0-----------
add: 116, delete: 55, change: 797, unhandled: 0 size_exceptions: 20 size_serialize: 0
-----------1.3.0RC0 vs 1.3.1RC0-----------
add: 11, delete: 0, change: 104, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.3.1RC0 vs 1.3.1RC1-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.3.1RC1 vs 1.3.2.1RC0-----------
add: 30, delete: 3, change: 260, unhandled: 0 size_exceptions: 6 size_serialize: 0
-----------1.3.2.1RC0 vs 1.3.2RC0-----------
add: 0, delete: 1, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.3.2RC0 vs 1.3.2RC1-----------
add: 1, delete: 0, change: 6, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.3.2RC1 vs 1.3.3RC0-----------
add: 13, delete: 2, change: 232, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.3.3RC0 vs 1.3.4RC0-----------
add: 5, delete: 0, change: 25, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.3.4RC0 vs 1.3.5RC0-----------
add: 2, delete: 0, change: 40, unhandled: 0 size_exceptions: 21 size_serialize: 0
-----------1.3.5RC0 vs 1.3.6RC0-----------
add: 83, delete: 0, change: 160, unhandled: 0 size_exceptions: 8 size_serialize: 0
-----------1.3.6RC0 vs 1.3.6RC1-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.3.6RC1 vs 1.4.0RC0-----------
add: 203, delete: 138, change: 1015, unhandled: 0 size_exceptions: 43 size_serialize: 0
-----------1.4.0RC0 vs 1.4.0RC1-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.0RC1 vs 1.4.1RC0-----------
add: 6, delete: 0, change: 66, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.4.1RC0 vs 1.4.2RC0-----------
add: 5, delete: 2, change: 28, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.2RC0 vs 1.4.2RC1-----------
add: 2, delete: 1, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.2RC1 vs 1.4.3RC0-----------
add: 4, delete: 7, change: 27, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------1.4.3RC0 vs 1.4.4RC0-----------
add: 0, delete: 0, change: 19, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.4RC0 vs 1.4.5RC1-----------
add: 2, delete: 0, change: 51, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.4.5RC1 vs 1.4.5rc0-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.5rc0 vs 1.4.6RC0-----------
add: 7, delete: 0, change: 69, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------1.4.6RC0 vs 1.4.7RC0-----------
add: 1, delete: 0, change: 33, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.7RC0 vs 1.4.8RC0-----------
add: 4, delete: 0, change: 55, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.8RC0 vs 1.4.9RC0-----------
add: 12, delete: 2, change: 49, unhandled: 0 size_exceptions: 4 size_serialize: 0
-----------1.4.9RC0 vs 1.4.9RC1-----------
add: 0, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.9RC1 vs 1.4.10RC0-----------
add: 9, delete: 0, change: 98, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------1.4.10RC0 vs 1.4.10RC1-----------
add: 1, delete: 0, change: 38, unhandled: 0 size_exceptions: 23 size_serialize: 0
-----------1.4.10RC1 vs 1.4.11RC0-----------
add: 88, delete: 1, change: 200, unhandled: 0 size_exceptions: 9 size_serialize: 0
-----------1.4.11RC0 vs 1.4.12RC0-----------
add: 2, delete: 0, change: 52, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.4.12RC0 vs 1.5.0RC0-----------
add: 21, delete: 94, change: 491, unhandled: 0 size_exceptions: 42 size_serialize: 0
-----------1.5.0RC0 vs 1.5.0RC1-----------
add: 2, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.5.0RC1 vs 1.5.0RC2-----------
add: 0, delete: 0, change: 5, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.5.0RC2 vs 1.5.0RC3-----------
add: 8, delete: 0, change: 27, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------1.5.0RC3 vs 1.5.0RC4-----------
add: 105, delete: 2, change: 370, unhandled: 0 size_exceptions: 33 size_serialize: 0
-----------1.5.0RC4 vs 1.5.HBASE-22466.0RC1-----------
add: 1, delete: 96, change: 278, unhandled: 0 size_exceptions: 9 size_serialize: 0
-----------1.5.HBASE-22466.0RC1 vs 1.5.HBASE-22466.0RC3-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.5.HBASE-22466.0RC3 vs 1.5.HBASE-22466.0RC4-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------1.5.HBASE-22466.0RC4 vs 1.6.0RC0-----------
add: 121, delete: 1, change: 415, unhandled: 0 size_exceptions: 99 size_serialize: 0
-----------1.6.0RC0 vs 2.0.0-alpha-1RC0-----------
  public static RemoteProcedureException deserialize(byte[] bytes)
      throws InvalidProtocolBufferException {
    return fromProto(ForeignExceptionMessage.parseFrom(bytes));
  }

+++++++++++++++++++++++
  public static RemoteProcedureException deserialize(byte[] bytes) throws IOException {
    return fromProto(ForeignExceptionMessage.parseFrom(bytes));
  }

  protected void deserializeStateData(final InputStream stream) throws IOException {
    StateMachineProcedureData data = StateMachineProcedureData.parseDelimitedFrom(stream);
    stateCount = data.getStateCount();
    if (stateCount > 0) {
      states = new int[stateCount];
      for (int i = 0; i < stateCount; ++i) {
        states[i] = data.getState(i);
      }
    } else {
      states = null;
    }
+++++++++++++++++++++++
  protected void deserializeStateData(final InputStream stream) throws IOException {
    StateMachineProcedureData data = StateMachineProcedureData.parseDelimitedFrom(stream);
    stateCount = data.getStateCount();
    if (stateCount > 0) {
      states = new int[stateCount];
      for (int i = 0; i < stateCount; ++i) {
        states[i] = data.getState(i);
      }
      if (isEofState()) {
        stateFlow = Flow.NO_MORE_STATE;
      }
    } else {
      states = null;
    }
  public static ForeignException deserialize(byte[] bytes) throws InvalidProtocolBufferException {
    // figure out the data we need to pass
    ForeignExceptionMessage eem = ForeignExceptionMessage.parseFrom(bytes);
    GenericExceptionMessage gem = eem.getGenericException();
    StackTraceElement [] trace = ForeignException.toStackTrace(gem.getTraceList());
    ProxyThrowable dfe = new ProxyThrowable(gem.getMessage(), trace);
    ForeignException e = new ForeignException(eem.getSource(), dfe);
    return e;
  }

  /**
   * Unwind a serialized array of {@link StackTraceElementMessage}s to a
   * {@link StackTraceElement}s.
   * @param traceList list that was serialized
   * @return the deserialized list or <tt>null</tt> if it couldn't be unwound (e.g. wasn't set on
   *         the sender).
   */
+++++++++++++++++++++++
  public static ForeignException deserialize(byte[] bytes)
  throws IOException {
    // figure out the data we need to pass
    ForeignExceptionMessage eem = ForeignExceptionMessage.parseFrom(bytes);
    GenericExceptionMessage gem = eem.getGenericException();
    StackTraceElement [] trace = ForeignException.toStackTrace(gem.getTraceList());
    ProxyThrowable dfe = new ProxyThrowable(gem.getMessage(), trace);
    ForeignException e = new ForeignException(eem.getSource(), dfe);
    return e;
  }

  /**
   * Unwind a serialized array of {@link StackTraceElementMessage}s to a
   * {@link StackTraceElement}s.
   * @param traceList list that was serialized
   * @return the deserialized list or <tt>null</tt> if it couldn't be unwound (e.g. wasn't set on
   *         the sender).
   */
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    BlockType.TRAILER.readAndCheck(inputStream);

    if (majorVersion > 2
        || (majorVersion == 2 && minorVersion >= HFileReaderV2.PBUF_TRAILER_MINOR_VERSION)) {
      deserializeFromPB(inputStream);
    } else {
      deserializeFromWritable(inputStream);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    int version = inputStream.readInt();
    expectMajorVersion(extractMajorVersion(version));
    expectMinorVersion(extractMinorVersion(version));
  }

  /**
   * Deserialize the file trailer as protobuf
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    BlockType.TRAILER.readAndCheck(inputStream);

    if (majorVersion > 2
        || (majorVersion == 2 && minorVersion >= HFileReaderImpl.PBUF_TRAILER_MINOR_VERSION)) {
      deserializeFromPB(inputStream);
    } else {
      deserializeFromWritable(inputStream);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    int version = inputStream.readInt();
    expectMajorVersion(extractMajorVersion(version));
    expectMinorVersion(extractMinorVersion(version));
  }

  /**
   * Deserialize the file trailer as protobuf
   * @param inputStream
   * @throws IOException
   */
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(ByteStringer.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(UnsafeByteOperations.unsafeWrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.AddColumnFamilyStateData addCFMsg =
        MasterProcedureProtos.AddColumnFamilyStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(addCFMsg.getUserInfo());
    tableName = ProtobufUtil.toTableName(addCFMsg.getTableName());
    cfDescriptor = HColumnDescriptor.convert(addCFMsg.getColumnfamilySchema());
    if (addCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = HTableDescriptor.convert(addCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.AddColumnFamilyStateData addCFMsg =
        MasterProcedureProtos.AddColumnFamilyStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(addCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(addCFMsg.getTableName());
    cfDescriptor = ProtobufUtil.convertToHColumnDesc(addCFMsg.getColumnfamilySchema());
    if (addCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(addCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.AddColumnFamilyStateData.Builder addCFMsg =
        MasterProcedureProtos.AddColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(cfDescriptor.convert());
    if (unmodifiedHTableDescriptor != null) {
      addCFMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
    }

    addCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.AddColumnFamilyStateData.Builder addCFMsg =
        MasterProcedureProtos.AddColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(ProtobufUtil.convertToColumnFamilySchema(cfDescriptor));
    if (unmodifiedHTableDescriptor != null) {
      addCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    addCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData state =
      MasterProcedureProtos.CreateTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
    hTableDescriptor = HTableDescriptor.convert(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<HRegionInfo>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
  }

  @Override
+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData state =
      MasterProcedureProtos.CreateTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    hTableDescriptor = ProtobufUtil.convertToHTableDesc(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
        .setTableSchema(hTableDescriptor.convert());
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor));
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);
    MasterProcedureProtos.DeleteColumnFamilyStateData deleteCFMsg =
        MasterProcedureProtos.DeleteColumnFamilyStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(deleteCFMsg.getUserInfo());
    tableName = ProtobufUtil.toTableName(deleteCFMsg.getTableName());
    familyName = deleteCFMsg.getColumnfamilyName().toByteArray();

    if (deleteCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = HTableDescriptor.convert(deleteCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);
    MasterProcedureProtos.DeleteColumnFamilyStateData deleteCFMsg =
        MasterProcedureProtos.DeleteColumnFamilyStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(deleteCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(deleteCFMsg.getTableName());
    familyName = deleteCFMsg.getColumnfamilyName().toByteArray();

    if (deleteCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(deleteCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteColumnFamilyStateData.Builder deleteCFMsg =
        MasterProcedureProtos.DeleteColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilyName(ByteStringer.wrap(familyName));
    if (unmodifiedHTableDescriptor != null) {
      deleteCFMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
    }

    deleteCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteColumnFamilyStateData.Builder deleteCFMsg =
        MasterProcedureProtos.DeleteColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilyName(UnsafeByteOperations.unsafeWrap(familyName));
    if (unmodifiedHTableDescriptor != null) {
      deleteCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    deleteCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData state =
      MasterProcedureProtos.DeleteTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<HRegionInfo>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData state =
      MasterProcedureProtos.DeleteTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(disableTableMsg.getUserInfo());
    tableName = ProtobufUtil.toTableName(disableTableMsg.getTableName());
    skipTableStateCheck = disableTableMsg.getSkipTableStateCheck();
  }

  @Override
+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(disableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(disableTableMsg.getTableName());
    skipTableStateCheck = disableTableMsg.getSkipTableStateCheck();
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData.Builder disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    disableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData.Builder disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    disableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo());
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
    skipTableStateCheck = enableTableMsg.getSkipTableStateCheck();
  }

  @Override
+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
    skipTableStateCheck = enableTableMsg.getSkipTableStateCheck();
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    enableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    enableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyColumnFamilyStateData modifyCFMsg =
        MasterProcedureProtos.ModifyColumnFamilyStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(modifyCFMsg.getUserInfo());
    tableName = ProtobufUtil.toTableName(modifyCFMsg.getTableName());
    cfDescriptor = HColumnDescriptor.convert(modifyCFMsg.getColumnfamilySchema());
    if (modifyCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = HTableDescriptor.convert(modifyCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyColumnFamilyStateData modifyCFMsg =
        MasterProcedureProtos.ModifyColumnFamilyStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(modifyCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(modifyCFMsg.getTableName());
    cfDescriptor = ProtobufUtil.convertToHColumnDesc(modifyCFMsg.getColumnfamilySchema());
    if (modifyCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(modifyCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyColumnFamilyStateData.Builder modifyCFMsg =
        MasterProcedureProtos.ModifyColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(cfDescriptor.convert());
    if (unmodifiedHTableDescriptor != null) {
      modifyCFMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
    }

    modifyCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyColumnFamilyStateData.Builder modifyCFMsg =
        MasterProcedureProtos.ModifyColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(ProtobufUtil.convertToColumnFamilySchema(cfDescriptor));
    if (unmodifiedHTableDescriptor != null) {
      modifyCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    modifyCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo());
    modifiedHTableDescriptor = HTableDescriptor.convert(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor =
          HTableDescriptor.convert(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo()));
    modifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor =
          ProtobufUtil.convertToHTableDesc(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setModifiedTableSchema(modifiedHTableDescriptor.convert())
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify);

    if (unmodifiedHTableDescriptor != null) {
      modifyTableMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
    }

    modifyTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setModifiedTableSchema(ProtobufUtil.convertToTableSchema(modifiedHTableDescriptor))
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify);

    if (unmodifiedHTableDescriptor != null) {
      modifyTableMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    modifyTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData state =
      MasterProcedureProtos.TruncateTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
    if (state.hasTableSchema()) {
      hTableDescriptor = HTableDescriptor.convert(state.getTableSchema());
      tableName = hTableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<HRegionInfo>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData state =
      MasterProcedureProtos.TruncateTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    if (state.hasTableSchema()) {
      hTableDescriptor = ProtobufUtil.convertToHTableDesc(state.getTableSchema());
      tableName = hTableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData.Builder state =
      MasterProcedureProtos.TruncateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
        .setPreserveSplits(preserveSplits);
    if (hTableDescriptor != null) {
      state.setTableSchema(hTableDescriptor.convert());
    } else {
      state.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData.Builder state =
      MasterProcedureProtos.TruncateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setPreserveSplits(preserveSplits);
    if (hTableDescriptor != null) {
      state.setTableSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor));
    } else {
      state.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HTableDescriptor tableDescriptor = table.getTableDescriptor();
      HFileOutputFormat2.configureDataBlockEncoding(tableDescriptor, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat2
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyDataBlockEncodingMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, DataBlockEncoding> familyToDataBlockEncoding =
          getMockColumnFamiliesForDataBlockEncoding(numCfs);
      Table table = Mockito.mock(Table.class);
      setupMockColumnFamiliesForDataBlockEncoding(table,
          familyToDataBlockEncoding);
      HTableDescriptor tableDescriptor = table.getTableDescriptor();
      HFileOutputFormat2.configureDataBlockEncoding(tableDescriptor, conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], DataBlockEncoding> retrievedFamilyToDataBlockEncodingMap =
          HFileOutputFormat2
          .createFamilyDataBlockEncodingMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, DataBlockEncoding> entry : familyToDataBlockEncoding.entrySet()) {
        assertEquals("DataBlockEncoding configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToDataBlockEncodingMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat2.configureBlockSize(table.getTableDescriptor(), conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat2
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBlockSizeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Integer> familyToBlockSize =
          getMockColumnFamiliesForBlockSize(numCfs);
      Table table = Mockito.mock(Table.class);
      setupMockColumnFamiliesForBlockSize(table,
          familyToBlockSize);
      HFileOutputFormat2.configureBlockSize(table.getTableDescriptor(), conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], Integer> retrievedFamilyToBlockSizeMap =
          HFileOutputFormat2
              .createFamilyBlockSizeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Integer> entry : familyToBlockSize.entrySet()
          ) {
        assertEquals("BlockSize configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBlockSizeMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat2.configureCompression(conf, table.getTableDescriptor());

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat2
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyCompressionMap() throws IOException {
    for (int numCfs = 0; numCfs <= 3; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, Compression.Algorithm> familyToCompression =
          getMockColumnFamiliesForCompression(numCfs);
      Table table = Mockito.mock(Table.class);
      setupMockColumnFamiliesForCompression(table, familyToCompression);
      HFileOutputFormat2.configureCompression(conf, table.getTableDescriptor());

      // read back family specific compression setting from the configuration
      Map<byte[], Algorithm> retrievedFamilyToCompressionMap = HFileOutputFormat2
          .createFamilyCompressionMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, Algorithm> entry : familyToCompression.entrySet()) {
        assertEquals("Compression configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToCompressionMap.get(entry.getKey().getBytes()));
      }
    }
  }

  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      Table table = Mockito.mock(HTable.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat2.configureBloomType(table.getTableDescriptor(), conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat2
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

+++++++++++++++++++++++
  public void testSerializeDeserializeFamilyBloomTypeMap() throws IOException {
    for (int numCfs = 0; numCfs <= 2; numCfs++) {
      Configuration conf = new Configuration(this.util.getConfiguration());
      Map<String, BloomType> familyToBloomType =
          getMockColumnFamiliesForBloomType(numCfs);
      Table table = Mockito.mock(Table.class);
      setupMockColumnFamiliesForBloomType(table,
          familyToBloomType);
      HFileOutputFormat2.configureBloomType(table.getTableDescriptor(), conf);

      // read back family specific data block encoding settings from the
      // configuration
      Map<byte[], BloomType> retrievedFamilyToBloomTypeMap =
          HFileOutputFormat2
              .createFamilyBloomTypeMap(conf);

      // test that we have a value for all column families that matches with the
      // used mock values
      for (Entry<String, BloomType> entry : familyToBloomType.entrySet()) {
        assertEquals("BloomType configuration incorrect for column family:"
            + entry.getKey(), entry.getValue(),
            retrievedFamilyToBloomTypeMap.get(entry.getKey().getBytes()));
      }
    }
  }

add: 864, delete: 477, change: 2239, unhandled: 4 size_exceptions: 213 size_serialize: 27
-----------2.0.0-alpha-1RC0 vs 2.0.0-alpha-2RC0-----------
  protected void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    final MoveRegionStateData state = MoveRegionStateData.parseDelimitedFrom(stream);
    final HRegionInfo regionInfo = getRegion(); // Get it from super class deserialization.
    final ServerName sourceServer = ProtobufUtil.toServerName(state.getSourceServer());
    final ServerName destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    this.plan = new RegionPlan(regionInfo, sourceServer, destinationServer);
+++++++++++++++++++++++
  protected void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    final MoveRegionStateData state = MoveRegionStateData.parseDelimitedFrom(stream);
    final HRegionInfo regionInfo = getRegion(); // Get it from super class deserialization.
    final ServerName sourceServer = ProtobufUtil.toServerName(state.getSourceServer());
    final ServerName destinationServer = state.hasDestinationServer() ?
        ProtobufUtil.toServerName(state.getDestinationServer()) : null;
    this.plan = new RegionPlan(regionInfo, sourceServer, destinationServer);
  protected void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    final MoveRegionStateData.Builder state = MoveRegionStateData.newBuilder()
        // No need to serialize the HRegionInfo. The super class has the region.
        .setSourceServer(ProtobufUtil.toServerName(plan.getSource()))
        .setDestinationServer(ProtobufUtil.toServerName(plan.getDestination()));
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    final MoveRegionStateData.Builder state = MoveRegionStateData.newBuilder()
        // No need to serialize the HRegionInfo. The super class has the region.
        .setSourceServer(ProtobufUtil.toServerName(plan.getSource()));
    if (plan.getDestination() != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(plan.getDestination()));
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
add: 62, delete: 236, change: 960, unhandled: 2 size_exceptions: 26 size_serialize: 2
-----------2.0.0-alpha-2RC0 vs 2.0.0-alpha-3RC0-----------
  protected abstract void deserializeStateData(final InputStream stream)
    throws IOException;

  /**
   * The user should override this method if they need a lock on an Entity.
   * A lock can be anything, and it is up to the implementor. The Procedure
   * Framework will call this method just before it invokes {@link #execute(Object)}.
   * It calls {@link #releaseLock(Object)} after the call to execute.
   *
   * <p>If you need to hold the lock for the life of the Procdure -- i.e. you do not
   * want any other Procedure interfering while this Procedure is running, see
   * {@link #holdLock(Object)}.
   *
   * <p>Example: in our Master we can execute request in parallel for different tables.
   * We can create t1 and create t2 and these creates can be executed at the same time.
   * Anything else on t1/t2 is queued waiting that specific table create to happen.
   *
   * <p>There are 3 LockState:
   * <ul><li>LOCK_ACQUIRED should be returned when the proc has the lock and the proc is
   * ready to execute.</li>
   * <li>LOCK_YIELD_WAIT should be returned when the proc has not the lock and the framework
   * should take care of readding the procedure back to the runnable set for retry</li>
   * <li>LOCK_EVENT_WAIT should be returned when the proc has not the lock and someone will
   * take care of readding the procedure back to the runnable set when the lock is available.
   * </li></ul>
   * @return the lock state as described above.
   */
+++++++++++++++++++++++
  protected abstract void deserializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The user should override this method if they need a lock on an Entity.
   * A lock can be anything, and it is up to the implementor. The Procedure
   * Framework will call this method just before it invokes {@link #execute(Object)}.
   * It calls {@link #releaseLock(Object)} after the call to execute.
   *
   * <p>If you need to hold the lock for the life of the Procedure -- i.e. you do not
   * want any other Procedure interfering while this Procedure is running, see
   * {@link #holdLock(Object)}.
   *
   * <p>Example: in our Master we can execute request in parallel for different tables.
   * We can create t1 and create t2 and these creates can be executed at the same time.
   * Anything else on t1/t2 is queued waiting that specific table create to happen.
   *
   * <p>There are 3 LockState:
   * <ul><li>LOCK_ACQUIRED should be returned when the proc has the lock and the proc is
   * ready to execute.</li>
   * <li>LOCK_YIELD_WAIT should be returned when the proc has not the lock and the framework
   * should take care of readding the procedure back to the runnable set for retry</li>
   * <li>LOCK_EVENT_WAIT should be returned when the proc has not the lock and someone will
   * take care of readding the procedure back to the runnable set when the lock is available.
   * </li></ul>
   * @return the lock state as described above.
   */
  protected abstract void serializeStateData(final OutputStream stream)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param stream the stream that contains the user serialized data
   */
+++++++++++++++++++++++
  protected abstract void serializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
  public void deserializeStateData(final InputStream stream) {
    throw new UnsupportedOperationException();
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
  public void serializeStateData(final OutputStream stream) {
    throw new UnsupportedOperationException();
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
  }

  @Override
  protected void deserializeStateData(final InputStream stream) throws IOException {
    SequentialProcedureData data = SequentialProcedureData.parseDelimitedFrom(stream);
    executed = data.getExecuted();
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    SequentialProcedureData data = serializer.deserialize(SequentialProcedureData.class);
    executed = data.getExecuted();
  protected void serializeStateData(final OutputStream stream) throws IOException {
    SequentialProcedureData.Builder data = SequentialProcedureData.newBuilder();
    data.setExecuted(executed);
    data.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    SequentialProcedureData.Builder data = SequentialProcedureData.newBuilder();
    data.setExecuted(executed);
    serializer.serialize(data.build());
  }

  @Override
  protected void serializeStateData(final OutputStream stream) throws IOException {
    StateMachineProcedureData.Builder data = StateMachineProcedureData.newBuilder();
    for (int i = 0; i < stateCount; ++i) {
      data.addState(states[i]);
    }
    data.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    StateMachineProcedureData.Builder data = StateMachineProcedureData.newBuilder();
    for (int i = 0; i < stateCount; ++i) {
      data.addState(states[i]);
    }
    serializer.serialize(data.build());
  }

  @Override
  protected void deserializeStateData(final InputStream stream) throws IOException {
    StateMachineProcedureData data = StateMachineProcedureData.parseDelimitedFrom(stream);
    stateCount = data.getStateCount();
    if (stateCount > 0) {
      states = new int[stateCount];
      for (int i = 0; i < stateCount; ++i) {
        states[i] = data.getState(i);
      }
      if (isEofState()) {
        stateFlow = Flow.NO_MORE_STATE;
      }
    } else {
      states = null;
    }
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    StateMachineProcedureData data = serializer.deserialize(StateMachineProcedureData.class);
    stateCount = data.getStateCount();
    if (stateCount > 0) {
      states = new int[stateCount];
      for (int i = 0; i < stateCount; ++i) {
        states[i] = data.getState(i);
      }
      if (isEofState()) {
        stateFlow = Flow.NO_MORE_STATE;
      }
    } else {
      states = null;
    }
  public void deserializeStateData(final InputStream stream) throws IOException {
    final AssignRegionStateData state = AssignRegionStateData.parseDelimitedFrom(stream);
    setTransitionState(state.getTransitionState());
    setRegionInfo(HRegionInfo.convert(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(HRegionInfo.convert(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(HRegionInfo.convert(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(HRegionInfo.convert(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(InputStream stream) throws IOException {
    super.deserializeStateData(stream);
    final MasterProcedureProtos.GCMergedRegionsStateData msg =
        MasterProcedureProtos.GCMergedRegionsStateData.parseDelimitedFrom(stream);
    this.father = HRegionInfo.convert(msg.getParentA());
    this.mother = HRegionInfo.convert(msg.getParentB());
    this.mergedChild = HRegionInfo.convert(msg.getMergedChild());
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    final MasterProcedureProtos.GCMergedRegionsStateData msg =
        serializer.deserialize(MasterProcedureProtos.GCMergedRegionsStateData.class);
    this.father = HRegionInfo.convert(msg.getParentA());
    this.mother = HRegionInfo.convert(msg.getParentB());
    this.mergedChild = HRegionInfo.convert(msg.getMergedChild());
  }

  @Override
  protected void serializeStateData(OutputStream stream) throws IOException {
    super.serializeStateData(stream);
    final MasterProcedureProtos.GCMergedRegionsStateData.Builder msg =
        MasterProcedureProtos.GCMergedRegionsStateData.newBuilder().
        setParentA(HRegionInfo.convert(this.father)).
        setParentB(HRegionInfo.convert(this.mother)).
        setMergedChild(HRegionInfo.convert(this.mergedChild));
    msg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    final MasterProcedureProtos.GCMergedRegionsStateData.Builder msg =
        MasterProcedureProtos.GCMergedRegionsStateData.newBuilder().
        setParentA(HRegionInfo.convert(this.father)).
        setParentB(HRegionInfo.convert(this.mother)).
        setMergedChild(HRegionInfo.convert(this.mergedChild));
    serializer.serialize(msg.build());
  }

  @Override
  protected void deserializeStateData(InputStream stream) throws IOException {
    super.deserializeStateData(stream);
    final MasterProcedureProtos.GCRegionStateData msg =
        MasterProcedureProtos.GCRegionStateData.parseDelimitedFrom(stream);
    setRegion(HRegionInfo.convert(msg.getRegionInfo()));
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    final MasterProcedureProtos.GCRegionStateData msg =
        serializer.deserialize(MasterProcedureProtos.GCRegionStateData.class);
    setRegion(HRegionInfo.convert(msg.getRegionInfo()));
  }

  @Override
  protected void serializeStateData(OutputStream stream) throws IOException {
    super.serializeStateData(stream);
    // Double serialization of regionname. Superclass is also serializing. Fix.
    final MasterProcedureProtos.GCRegionStateData.Builder msg =
        MasterProcedureProtos.GCRegionStateData.newBuilder()
        .setRegionInfo(HRegionInfo.convert(getRegion()));
    msg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    // Double serialization of regionname. Superclass is also serializing. Fix.
    final MasterProcedureProtos.GCRegionStateData.Builder msg =
        MasterProcedureProtos.GCRegionStateData.newBuilder()
        .setRegionInfo(HRegionInfo.convert(getRegion()));
    serializer.serialize(msg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    final MasterProcedureProtos.MergeTableRegionsStateData mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(mergeTableRegionsMsg.getUserInfo()));

    assert(mergeTableRegionsMsg.getRegionInfoCount() == 2);
    regionsToMerge = new HRegionInfo[mergeTableRegionsMsg.getRegionInfoCount()];
    for (int i = 0; i < regionsToMerge.length; i++) {
      regionsToMerge[i] = HRegionInfo.convert(mergeTableRegionsMsg.getRegionInfo(i));
    }

    mergedRegion = HRegionInfo.convert(mergeTableRegionsMsg.getMergedRegionInfo());
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData mergeTableRegionsMsg =
        serializer.deserialize(MasterProcedureProtos.MergeTableRegionsStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(mergeTableRegionsMsg.getUserInfo()));

    assert(mergeTableRegionsMsg.getRegionInfoCount() == 2);
    regionsToMerge = new HRegionInfo[mergeTableRegionsMsg.getRegionInfoCount()];
    for (int i = 0; i < regionsToMerge.length; i++) {
      regionsToMerge[i] = HRegionInfo.convert(mergeTableRegionsMsg.getRegionInfo(i));
    }

    mergedRegion = HRegionInfo.convert(mergeTableRegionsMsg.getMergedRegionInfo());
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(HRegionInfo.convert(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(HRegionInfo.convert(regionsToMerge[i]));
    }
    mergeTableRegionsMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(HRegionInfo.convert(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(HRegionInfo.convert(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
  protected void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    final MoveRegionStateData state = MoveRegionStateData.parseDelimitedFrom(stream);
    final HRegionInfo regionInfo = getRegion(); // Get it from super class deserialization.
    final ServerName sourceServer = ProtobufUtil.toServerName(state.getSourceServer());
    final ServerName destinationServer = state.hasDestinationServer() ?
        ProtobufUtil.toServerName(state.getDestinationServer()) : null;
    this.plan = new RegionPlan(regionInfo, sourceServer, destinationServer);
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MoveRegionStateData state = serializer.deserialize(MoveRegionStateData.class);
    final HRegionInfo regionInfo = getRegion(); // Get it from super class deserialization.
    final ServerName sourceServer = ProtobufUtil.toServerName(state.getSourceServer());
    final ServerName destinationServer = state.hasDestinationServer() ?
        ProtobufUtil.toServerName(state.getDestinationServer()) : null;
    this.plan = new RegionPlan(regionInfo, sourceServer, destinationServer);
  protected void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    final MoveRegionStateData.Builder state = MoveRegionStateData.newBuilder()
        // No need to serialize the HRegionInfo. The super class has the region.
        .setSourceServer(ProtobufUtil.toServerName(plan.getSource()));
    if (plan.getDestination() != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(plan.getDestination()));
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MoveRegionStateData.Builder state = MoveRegionStateData.newBuilder()
        // No need to serialize the HRegionInfo. The super class has the region.
        .setSourceServer(ProtobufUtil.toServerName(plan.getSource()));
    if (plan.getDestination() != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(plan.getDestination()));
    }

    serializer.serialize(state.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    final MasterProcedureProtos.SplitTableRegionStateData splitTableRegionsMsg =
        MasterProcedureProtos.SplitTableRegionStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(splitTableRegionsMsg.getUserInfo()));
    setRegion(HRegionInfo.convert(splitTableRegionsMsg.getParentRegionInfo()));
    assert(splitTableRegionsMsg.getChildRegionInfoCount() == 2);
    daughter_1_HRI = HRegionInfo.convert(splitTableRegionsMsg.getChildRegionInfo(0));
    daughter_2_HRI = HRegionInfo.convert(splitTableRegionsMsg.getChildRegionInfo(1));
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MasterProcedureProtos.SplitTableRegionStateData splitTableRegionsMsg =
        serializer.deserialize(MasterProcedureProtos.SplitTableRegionStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(splitTableRegionsMsg.getUserInfo()));
    setRegion(HRegionInfo.convert(splitTableRegionsMsg.getParentRegionInfo()));
    assert(splitTableRegionsMsg.getChildRegionInfoCount() == 2);
    daughter_1_HRI = HRegionInfo.convert(splitTableRegionsMsg.getChildRegionInfo(0));
    daughter_2_HRI = HRegionInfo.convert(splitTableRegionsMsg.getChildRegionInfo(1));
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    final MasterProcedureProtos.SplitTableRegionStateData.Builder splitTableRegionMsg =
        MasterProcedureProtos.SplitTableRegionStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setParentRegionInfo(HRegionInfo.convert(getRegion()))
        .addChildRegionInfo(HRegionInfo.convert(daughter_1_HRI))
        .addChildRegionInfo(HRegionInfo.convert(daughter_2_HRI));
    splitTableRegionMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.SplitTableRegionStateData.Builder splitTableRegionMsg =
        MasterProcedureProtos.SplitTableRegionStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setParentRegionInfo(HRegionInfo.convert(getRegion()))
        .addChildRegionInfo(HRegionInfo.convert(daughter_1_HRI))
        .addChildRegionInfo(HRegionInfo.convert(daughter_2_HRI));
    serializer.serialize(splitTableRegionMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    final UnassignRegionStateData state = UnassignRegionStateData.parseDelimitedFrom(stream);
    setTransitionState(state.getTransitionState());
    setRegionInfo(HRegionInfo.convert(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(HRegionInfo.convert(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(HRegionInfo.convert(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(HRegionInfo.convert(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(final InputStream stream) throws IOException {
    final LockProcedureData state = LockProcedureData.parseDelimitedFrom(stream);
    type = LockType.valueOf(state.getLockType().name());
    description = state.getDescription();
    if (state.getRegionInfoCount() > 0) {
      regionInfos = new HRegionInfo[state.getRegionInfoCount()];
      for (int i = 0; i < state.getRegionInfoCount(); ++i) {
        regionInfos[i] = HRegionInfo.convert(state.getRegionInfo(i));
      }
    } else if (state.hasNamespace()) {
      namespace = state.getNamespace();
    } else if (state.hasTableName()) {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    recoveredMasterLock = state.getIsMasterLock();
    this.lock = setupLock();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final LockProcedureData state = serializer.deserialize(LockProcedureData.class);
    type = LockType.valueOf(state.getLockType().name());
    description = state.getDescription();
    if (state.getRegionInfoCount() > 0) {
      regionInfos = new HRegionInfo[state.getRegionInfoCount()];
      for (int i = 0; i < state.getRegionInfoCount(); ++i) {
        regionInfos[i] = HRegionInfo.convert(state.getRegionInfo(i));
      }
    } else if (state.hasNamespace()) {
      namespace = state.getNamespace();
    } else if (state.hasTableName()) {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    recoveredMasterLock = state.getIsMasterLock();
    this.lock = setupLock();
  }

  @Override
  protected void serializeStateData(final OutputStream stream) throws IOException {
    final LockProcedureData.Builder builder = LockProcedureData.newBuilder()
          .setLockType(LockServiceProtos.LockType.valueOf(type.name()))
          .setDescription(description);
    if (regionInfos != null) {
      for (int i = 0; i < regionInfos.length; ++i) {
        builder.addRegionInfo(HRegionInfo.convert(regionInfos[i]));
      }
    } else if (namespace != null) {
      builder.setNamespace(namespace);
    } else if (tableName != null) {
      builder.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (lockAcquireLatch != null) {
      builder.setIsMasterLock(true);
    }
    builder.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final LockProcedureData.Builder builder = LockProcedureData.newBuilder()
          .setLockType(LockServiceProtos.LockType.valueOf(type.name()))
          .setDescription(description);
    if (regionInfos != null) {
      for (int i = 0; i < regionInfos.length; ++i) {
        builder.addRegionInfo(HRegionInfo.convert(regionInfos[i]));
      }
    } else if (namespace != null) {
      builder.setNamespace(namespace);
    } else if (tableName != null) {
      builder.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (lockAcquireLatch != null) {
      builder.setIsMasterLock(true);
    }
    serializer.serialize(builder.build());
  }

  @Override
  protected void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);
    this.hri = HRegionInfo.convert(HBaseProtos.RegionInfo.parseDelimitedFrom(stream));
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    this.hri = HRegionInfo.convert(serializer.deserialize(HBaseProtos.RegionInfo.class));
  protected void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);
    HRegionInfo.convert(getRegion()).writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    serializer.serialize(HRegionInfo.convert(getRegion()));
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.AddColumnFamilyStateData addCFMsg =
        MasterProcedureProtos.AddColumnFamilyStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(addCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(addCFMsg.getTableName());
    cfDescriptor = ProtobufUtil.convertToHColumnDesc(addCFMsg.getColumnfamilySchema());
    if (addCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(addCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.AddColumnFamilyStateData addCFMsg =
        serializer.deserialize(MasterProcedureProtos.AddColumnFamilyStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(addCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(addCFMsg.getTableName());
    cfDescriptor = ProtobufUtil.toColumnFamilyDescriptor(addCFMsg.getColumnfamilySchema());
    if (addCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedTableDescriptor = ProtobufUtil.toTableDescriptor(addCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.AddColumnFamilyStateData.Builder addCFMsg =
        MasterProcedureProtos.AddColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(ProtobufUtil.convertToColumnFamilySchema(cfDescriptor));
    if (unmodifiedHTableDescriptor != null) {
      addCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    addCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.AddColumnFamilyStateData.Builder addCFMsg =
        MasterProcedureProtos.AddColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(ProtobufUtil.toColumnFamilySchema(cfDescriptor));
    if (unmodifiedTableDescriptor != null) {
      addCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.toTableSchema(unmodifiedTableDescriptor));
    }

    serializer.serialize(addCFMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.CloneSnapshotStateData cloneSnapshotMsg =
      MasterProcedureProtos.CloneSnapshotStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(cloneSnapshotMsg.getUserInfo()));
    snapshot = cloneSnapshotMsg.getSnapshot();
    hTableDescriptor = ProtobufUtil.convertToHTableDesc(cloneSnapshotMsg.getTableSchema());
    if (cloneSnapshotMsg.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(cloneSnapshotMsg.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: cloneSnapshotMsg.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
    if (cloneSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      parentsToChildrenPairMap = new HashMap<>();
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        cloneSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
    // Make sure that the monitor status is set up
    getMonitorStatus();
  }

  /**
   * Action before any real action of cloning from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CloneSnapshotStateData cloneSnapshotMsg =
        serializer.deserialize(MasterProcedureProtos.CloneSnapshotStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(cloneSnapshotMsg.getUserInfo()));
    snapshot = cloneSnapshotMsg.getSnapshot();
    tableDescriptor = ProtobufUtil.toTableDescriptor(cloneSnapshotMsg.getTableSchema());
    if (cloneSnapshotMsg.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(cloneSnapshotMsg.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: cloneSnapshotMsg.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
    if (cloneSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      parentsToChildrenPairMap = new HashMap<>();
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        cloneSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
    // Make sure that the monitor status is set up
    getMonitorStatus();
  }

  /**
   * Action before any real action of cloning from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.CloneSnapshotStateData.Builder cloneSnapshotMsg =
      MasterProcedureProtos.CloneSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setTableSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor));
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        cloneSnapshotMsg.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        cloneSnapshotMsg.addParentToChildRegionsPairList(parentToChildrenPair);
      }
    }
    cloneSnapshotMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CloneSnapshotStateData.Builder cloneSnapshotMsg =
      MasterProcedureProtos.CloneSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        cloneSnapshotMsg.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        cloneSnapshotMsg.addParentToChildRegionsPairList(parentToChildrenPair);
      }
    }
    serializer.serialize(cloneSnapshotMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.CreateNamespaceStateData createNamespaceMsg =
        MasterProcedureProtos.CreateNamespaceStateData.parseDelimitedFrom(stream);
    nsDescriptor = ProtobufUtil.toNamespaceDescriptor(createNamespaceMsg.getNamespaceDescriptor());
  }

+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CreateNamespaceStateData createNamespaceMsg =
        serializer.deserialize(MasterProcedureProtos.CreateNamespaceStateData.class);
    nsDescriptor = ProtobufUtil.toNamespaceDescriptor(createNamespaceMsg.getNamespaceDescriptor());
  }

  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.CreateNamespaceStateData.Builder createNamespaceMsg =
        MasterProcedureProtos.CreateNamespaceStateData.newBuilder().setNamespaceDescriptor(
          ProtobufUtil.toProtoNamespaceDescriptor(this.nsDescriptor));
    createNamespaceMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CreateNamespaceStateData.Builder createNamespaceMsg =
        MasterProcedureProtos.CreateNamespaceStateData.newBuilder().setNamespaceDescriptor(
          ProtobufUtil.toProtoNamespaceDescriptor(this.nsDescriptor));
    serializer.serialize(createNamespaceMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData state =
      MasterProcedureProtos.CreateTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    hTableDescriptor = ProtobufUtil.convertToHTableDesc(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.CreateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor));
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);
    MasterProcedureProtos.DeleteColumnFamilyStateData deleteCFMsg =
        MasterProcedureProtos.DeleteColumnFamilyStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(deleteCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(deleteCFMsg.getTableName());
    familyName = deleteCFMsg.getColumnfamilyName().toByteArray();

    if (deleteCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(deleteCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    MasterProcedureProtos.DeleteColumnFamilyStateData deleteCFMsg =
        serializer.deserialize(MasterProcedureProtos.DeleteColumnFamilyStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(deleteCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(deleteCFMsg.getTableName());
    familyName = deleteCFMsg.getColumnfamilyName().toByteArray();

    if (deleteCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedTableDescriptor = ProtobufUtil.toTableDescriptor(deleteCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteColumnFamilyStateData.Builder deleteCFMsg =
        MasterProcedureProtos.DeleteColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilyName(UnsafeByteOperations.unsafeWrap(familyName));
    if (unmodifiedHTableDescriptor != null) {
      deleteCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    deleteCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DeleteColumnFamilyStateData.Builder deleteCFMsg =
        MasterProcedureProtos.DeleteColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilyName(UnsafeByteOperations.unsafeWrap(familyName));
    if (unmodifiedTableDescriptor != null) {
      deleteCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.toTableSchema(unmodifiedTableDescriptor));
    }

    serializer.serialize(deleteCFMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DeleteNamespaceStateData deleteNamespaceMsg =
        MasterProcedureProtos.DeleteNamespaceStateData.parseDelimitedFrom(stream);
    namespaceName = deleteNamespaceMsg.getNamespaceName();
    if (deleteNamespaceMsg.hasNamespaceDescriptor()) {
      nsDescriptor =
          ProtobufUtil.toNamespaceDescriptor(deleteNamespaceMsg.getNamespaceDescriptor());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.DeleteNamespaceStateData deleteNamespaceMsg =
        serializer.deserialize(MasterProcedureProtos.DeleteNamespaceStateData.class);
    namespaceName = deleteNamespaceMsg.getNamespaceName();
    if (deleteNamespaceMsg.hasNamespaceDescriptor()) {
      nsDescriptor =
          ProtobufUtil.toNamespaceDescriptor(deleteNamespaceMsg.getNamespaceDescriptor());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteNamespaceStateData.Builder deleteNamespaceMsg =
        MasterProcedureProtos.DeleteNamespaceStateData.newBuilder().setNamespaceName(namespaceName);
    if (this.nsDescriptor != null) {
      deleteNamespaceMsg.setNamespaceDescriptor(
        ProtobufUtil.toProtoNamespaceDescriptor(this.nsDescriptor));
    }
    deleteNamespaceMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DeleteNamespaceStateData.Builder deleteNamespaceMsg =
        MasterProcedureProtos.DeleteNamespaceStateData.newBuilder().setNamespaceName(namespaceName);
    if (this.nsDescriptor != null) {
      deleteNamespaceMsg.setNamespaceDescriptor(
        ProtobufUtil.toProtoNamespaceDescriptor(this.nsDescriptor));
    }
    serializer.serialize(deleteNamespaceMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData state =
      MasterProcedureProtos.DeleteTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData state =
        serializer.deserialize(MasterProcedureProtos.DeleteTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(disableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(disableTableMsg.getTableName());
    skipTableStateCheck = disableTableMsg.getSkipTableStateCheck();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.DisableTableStateData disableTableMsg =
        serializer.deserialize(MasterProcedureProtos.DisableTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(disableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(disableTableMsg.getTableName());
    skipTableStateCheck = disableTableMsg.getSkipTableStateCheck();
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData.Builder disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    disableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DisableTableStateData.Builder disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    serializer.serialize(disableTableMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
    skipTableStateCheck = enableTableMsg.getSkipTableStateCheck();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
        serializer.deserialize(MasterProcedureProtos.EnableTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
    skipTableStateCheck = enableTableMsg.getSkipTableStateCheck();
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    enableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    serializer.serialize(enableTableMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyColumnFamilyStateData modifyCFMsg =
        MasterProcedureProtos.ModifyColumnFamilyStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(modifyCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(modifyCFMsg.getTableName());
    cfDescriptor = ProtobufUtil.convertToHColumnDesc(modifyCFMsg.getColumnfamilySchema());
    if (modifyCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(modifyCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ModifyColumnFamilyStateData modifyCFMsg =
        serializer.deserialize(MasterProcedureProtos.ModifyColumnFamilyStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(modifyCFMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(modifyCFMsg.getTableName());
    cfDescriptor = ProtobufUtil.toColumnFamilyDescriptor(modifyCFMsg.getColumnfamilySchema());
    if (modifyCFMsg.hasUnmodifiedTableSchema()) {
      unmodifiedtableDescriptor = ProtobufUtil.toTableDescriptor(modifyCFMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyColumnFamilyStateData.Builder modifyCFMsg =
        MasterProcedureProtos.ModifyColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(ProtobufUtil.convertToColumnFamilySchema(cfDescriptor));
    if (unmodifiedHTableDescriptor != null) {
      modifyCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    modifyCFMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ModifyColumnFamilyStateData.Builder modifyCFMsg =
        MasterProcedureProtos.ModifyColumnFamilyStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setColumnfamilySchema(ProtobufUtil.toColumnFamilySchema(cfDescriptor));
    if (unmodifiedtableDescriptor != null) {
      modifyCFMsg
          .setUnmodifiedTableSchema(ProtobufUtil.toTableSchema(unmodifiedtableDescriptor));
    }

    serializer.serialize(modifyCFMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyNamespaceStateData modifyNamespaceMsg =
        MasterProcedureProtos.ModifyNamespaceStateData.parseDelimitedFrom(stream);
    newNsDescriptor =
        ProtobufUtil.toNamespaceDescriptor(modifyNamespaceMsg.getNamespaceDescriptor());
    if (modifyNamespaceMsg.hasUnmodifiedNamespaceDescriptor()) {
      oldNsDescriptor =
          ProtobufUtil.toNamespaceDescriptor(modifyNamespaceMsg.getUnmodifiedNamespaceDescriptor());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ModifyNamespaceStateData modifyNamespaceMsg =
        serializer.deserialize(MasterProcedureProtos.ModifyNamespaceStateData.class);
    newNsDescriptor =
        ProtobufUtil.toNamespaceDescriptor(modifyNamespaceMsg.getNamespaceDescriptor());
    if (modifyNamespaceMsg.hasUnmodifiedNamespaceDescriptor()) {
      oldNsDescriptor =
          ProtobufUtil.toNamespaceDescriptor(modifyNamespaceMsg.getUnmodifiedNamespaceDescriptor());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyNamespaceStateData.Builder modifyNamespaceMsg =
        MasterProcedureProtos.ModifyNamespaceStateData.newBuilder().setNamespaceDescriptor(
          ProtobufUtil.toProtoNamespaceDescriptor(this.newNsDescriptor));
    if (this.oldNsDescriptor != null) {
      modifyNamespaceMsg.setUnmodifiedNamespaceDescriptor(
        ProtobufUtil.toProtoNamespaceDescriptor(this.oldNsDescriptor));
    }
    modifyNamespaceMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ModifyNamespaceStateData.Builder modifyNamespaceMsg =
        MasterProcedureProtos.ModifyNamespaceStateData.newBuilder().setNamespaceDescriptor(
          ProtobufUtil.toProtoNamespaceDescriptor(this.newNsDescriptor));
    if (this.oldNsDescriptor != null) {
      modifyNamespaceMsg.setUnmodifiedNamespaceDescriptor(
        ProtobufUtil.toProtoNamespaceDescriptor(this.oldNsDescriptor));
    }
    serializer.serialize(modifyNamespaceMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo()));
    modifiedHTableDescriptor = ProtobufUtil.convertToHTableDesc(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor =
          ProtobufUtil.convertToHTableDesc(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        serializer.deserialize(MasterProcedureProtos.ModifyTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo()));
    modifiedTableDescriptor = ProtobufUtil.toTableDescriptor(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedTableDescriptor =
          ProtobufUtil.toTableDescriptor(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setModifiedTableSchema(ProtobufUtil.convertToTableSchema(modifiedHTableDescriptor))
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify);

    if (unmodifiedHTableDescriptor != null) {
      modifyTableMsg
          .setUnmodifiedTableSchema(ProtobufUtil.convertToTableSchema(unmodifiedHTableDescriptor));
    }

    modifyTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setModifiedTableSchema(ProtobufUtil.toTableSchema(modifiedTableDescriptor))
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify);

    if (unmodifiedTableDescriptor != null) {
      modifyTableMsg
          .setUnmodifiedTableSchema(ProtobufUtil.toTableSchema(unmodifiedTableDescriptor));
    }

    serializer.serialize(modifyTableMsg.build());
  }

  @Override
  protected void deserializeStateData(InputStream stream) throws IOException {
    super.deserializeStateData(stream);
    MasterProcedureProtos.RecoverMetaStateData state =
        MasterProcedureProtos.RecoverMetaStateData.parseDelimitedFrom(stream);
    this.shouldSplitWal = state.hasShouldSplitWal() && state.getShouldSplitWal();
    this.failedMetaServer = state.hasFailedMetaServer() ?
        ProtobufUtil.toServerName(state.getFailedMetaServer()) : null;
    this.replicaId = state.hasReplicaId() ? state.getReplicaId() : HRegionInfo.DEFAULT_REPLICA_ID;
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    MasterProcedureProtos.RecoverMetaStateData state =
        serializer.deserialize(MasterProcedureProtos.RecoverMetaStateData.class);
    this.shouldSplitWal = state.hasShouldSplitWal() && state.getShouldSplitWal();
    this.failedMetaServer = state.hasFailedMetaServer() ?
        ProtobufUtil.toServerName(state.getFailedMetaServer()) : null;
    this.replicaId = state.hasReplicaId() ? state.getReplicaId() : HRegionInfo.DEFAULT_REPLICA_ID;
  }

  @Override
  protected void serializeStateData(OutputStream stream) throws IOException {
    super.serializeStateData(stream);
    MasterProcedureProtos.RecoverMetaStateData.Builder state =
        MasterProcedureProtos.RecoverMetaStateData.newBuilder().setShouldSplitWal(shouldSplitWal);
    if (failedMetaServer != null) {
      state.setFailedMetaServer(ProtobufUtil.toServerName(failedMetaServer));
    }
    state.setReplicaId(replicaId);
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    MasterProcedureProtos.RecoverMetaStateData.Builder state =
        MasterProcedureProtos.RecoverMetaStateData.newBuilder().setShouldSplitWal(shouldSplitWal);
    if (failedMetaServer != null) {
      state.setFailedMetaServer(ProtobufUtil.toServerName(failedMetaServer));
    }
    state.setReplicaId(replicaId);
    serializer.serialize(state.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.RestoreSnapshotStateData restoreSnapshotMsg =
      MasterProcedureProtos.RestoreSnapshotStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(restoreSnapshotMsg.getUserInfo()));
    snapshot = restoreSnapshotMsg.getSnapshot();
    modifiedHTableDescriptor =
      ProtobufUtil.convertToHTableDesc(restoreSnapshotMsg.getModifiedTableSchema());

    if (restoreSnapshotMsg.getRegionInfoForRestoreCount() == 0) {
      regionsToRestore = null;
    } else {
      regionsToRestore = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRestoreCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRestoreList()) {
        regionsToRestore.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForRemoveCount() == 0) {
      regionsToRemove = null;
    } else {
      regionsToRemove = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRemoveCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRemoveList()) {
        regionsToRemove.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForAddCount() == 0) {
      regionsToAdd = null;
    } else {
      regionsToAdd = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForAddCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForAddList()) {
        regionsToAdd.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        restoreSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
  }

  /**
   * Action before any real action of restoring from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.RestoreSnapshotStateData restoreSnapshotMsg =
        serializer.deserialize(MasterProcedureProtos.RestoreSnapshotStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(restoreSnapshotMsg.getUserInfo()));
    snapshot = restoreSnapshotMsg.getSnapshot();
    modifiedTableDescriptor =
      ProtobufUtil.toTableDescriptor(restoreSnapshotMsg.getModifiedTableSchema());

    if (restoreSnapshotMsg.getRegionInfoForRestoreCount() == 0) {
      regionsToRestore = null;
    } else {
      regionsToRestore = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRestoreCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRestoreList()) {
        regionsToRestore.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForRemoveCount() == 0) {
      regionsToRemove = null;
    } else {
      regionsToRemove = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRemoveCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRemoveList()) {
        regionsToRemove.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForAddCount() == 0) {
      regionsToAdd = null;
    } else {
      regionsToAdd = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForAddCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForAddList()) {
        regionsToAdd.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        restoreSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
  }

  /**
   * Action before any real action of restoring from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.RestoreSnapshotStateData.Builder restoreSnapshotMsg =
      MasterProcedureProtos.RestoreSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setModifiedTableSchema(ProtobufUtil.convertToTableSchema(modifiedHTableDescriptor));

    if (regionsToRestore != null) {
      for (HRegionInfo hri: regionsToRestore) {
        restoreSnapshotMsg.addRegionInfoForRestore(HRegionInfo.convert(hri));
      }
    }
    if (regionsToRemove != null) {
      for (HRegionInfo hri: regionsToRemove) {
        restoreSnapshotMsg.addRegionInfoForRemove(HRegionInfo.convert(hri));
      }
    }
    if (regionsToAdd != null) {
      for (HRegionInfo hri: regionsToAdd) {
        restoreSnapshotMsg.addRegionInfoForAdd(HRegionInfo.convert(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        restoreSnapshotMsg.addParentToChildRegionsPairList (parentToChildrenPair);
      }
    }
    restoreSnapshotMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.RestoreSnapshotStateData.Builder restoreSnapshotMsg =
      MasterProcedureProtos.RestoreSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setModifiedTableSchema(ProtobufUtil.toTableSchema(modifiedTableDescriptor));

    if (regionsToRestore != null) {
      for (HRegionInfo hri: regionsToRestore) {
        restoreSnapshotMsg.addRegionInfoForRestore(HRegionInfo.convert(hri));
      }
    }
    if (regionsToRemove != null) {
      for (HRegionInfo hri: regionsToRemove) {
        restoreSnapshotMsg.addRegionInfoForRemove(HRegionInfo.convert(hri));
      }
    }
    if (regionsToAdd != null) {
      for (HRegionInfo hri: regionsToAdd) {
        restoreSnapshotMsg.addRegionInfoForAdd(HRegionInfo.convert(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        restoreSnapshotMsg.addParentToChildRegionsPairList (parentToChildrenPair);
      }
    }
    serializer.serialize(restoreSnapshotMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ServerCrashStateData state =
      MasterProcedureProtos.ServerCrashStateData.parseDelimitedFrom(stream);
    this.serverName = ProtobufUtil.toServerName(state.getServerName());
    this.carryingMeta = state.hasCarryingMeta()? state.getCarryingMeta(): false;
    // shouldSplitWAL has a default over in pb so this invocation will always work.
    this.shouldSplitWal = state.getShouldSplitWal();
    int size = state.getRegionsOnCrashedServerCount();
    if (size > 0) {
      this.regionsOnCrashedServer = new ArrayList<HRegionInfo>(size);
      for (RegionInfo ri: state.getRegionsOnCrashedServerList()) {
        this.regionsOnCrashedServer.add(HRegionInfo.convert(ri));
      }
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData state =
        serializer.deserialize(MasterProcedureProtos.ServerCrashStateData.class);
    this.serverName = ProtobufUtil.toServerName(state.getServerName());
    this.carryingMeta = state.hasCarryingMeta()? state.getCarryingMeta(): false;
    // shouldSplitWAL has a default over in pb so this invocation will always work.
    this.shouldSplitWal = state.getShouldSplitWal();
    int size = state.getRegionsOnCrashedServerCount();
    if (size > 0) {
      this.regionsOnCrashedServer = new ArrayList<HRegionInfo>(size);
      for (RegionInfo ri: state.getRegionsOnCrashedServerList()) {
        this.regionsOnCrashedServer.add(HRegionInfo.convert(ri));
      }
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ServerCrashStateData.Builder state =
      MasterProcedureProtos.ServerCrashStateData.newBuilder().
      setServerName(ProtobufUtil.toServerName(this.serverName)).
      setCarryingMeta(this.carryingMeta).
      setShouldSplitWal(this.shouldSplitWal);
    if (this.regionsOnCrashedServer != null && !this.regionsOnCrashedServer.isEmpty()) {
      for (HRegionInfo hri: this.regionsOnCrashedServer) {
        state.addRegionsOnCrashedServer(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData.Builder state =
      MasterProcedureProtos.ServerCrashStateData.newBuilder().
      setServerName(ProtobufUtil.toServerName(this.serverName)).
      setCarryingMeta(this.carryingMeta).
      setShouldSplitWal(this.shouldSplitWal);
    if (this.regionsOnCrashedServer != null && !this.regionsOnCrashedServer.isEmpty()) {
      for (HRegionInfo hri: this.regionsOnCrashedServer) {
        state.addRegionsOnCrashedServer(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData state =
      MasterProcedureProtos.TruncateTableStateData.parseDelimitedFrom(stream);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    if (state.hasTableSchema()) {
      hTableDescriptor = ProtobufUtil.convertToHTableDesc(state.getTableSchema());
      tableName = hTableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.TruncateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.TruncateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    if (state.hasTableSchema()) {
      tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
      tableName = tableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData.Builder state =
      MasterProcedureProtos.TruncateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setPreserveSplits(preserveSplits);
    if (hTableDescriptor != null) {
      state.setTableSchema(ProtobufUtil.convertToTableSchema(hTableDescriptor));
    } else {
      state.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.TruncateTableStateData.Builder state =
      MasterProcedureProtos.TruncateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setPreserveSplits(preserveSplits);
    if (tableDescriptor != null) {
      state.setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    } else {
      state.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
add: 286, delete: 251, change: 2098, unhandled: 6 size_exceptions: 14 size_serialize: 58
-----------2.0.0-alpha-3RC0 vs 2.0.0-alpha-3RC0.2-----------
add: 2, delete: 5, change: 59, unhandled: 0 size_exceptions: 7 size_serialize: 0
-----------2.0.0-alpha-3RC0.2 vs 2.0.0-alpha4RC0-----------
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(HRegionInfo.convert(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(HRegionInfo.convert(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    final MasterProcedureProtos.GCMergedRegionsStateData msg =
        serializer.deserialize(MasterProcedureProtos.GCMergedRegionsStateData.class);
    this.father = HRegionInfo.convert(msg.getParentA());
    this.mother = HRegionInfo.convert(msg.getParentB());
    this.mergedChild = HRegionInfo.convert(msg.getMergedChild());
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    final MasterProcedureProtos.GCMergedRegionsStateData msg =
        serializer.deserialize(MasterProcedureProtos.GCMergedRegionsStateData.class);
    this.father = ProtobufUtil.toRegionInfo(msg.getParentA());
    this.mother = ProtobufUtil.toRegionInfo(msg.getParentB());
    this.mergedChild = ProtobufUtil.toRegionInfo(msg.getMergedChild());
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    final MasterProcedureProtos.GCMergedRegionsStateData.Builder msg =
        MasterProcedureProtos.GCMergedRegionsStateData.newBuilder().
        setParentA(HRegionInfo.convert(this.father)).
        setParentB(HRegionInfo.convert(this.mother)).
        setMergedChild(HRegionInfo.convert(this.mergedChild));
    serializer.serialize(msg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    final MasterProcedureProtos.GCMergedRegionsStateData.Builder msg =
        MasterProcedureProtos.GCMergedRegionsStateData.newBuilder().
        setParentA(ProtobufUtil.toRegionInfo(this.father)).
        setParentB(ProtobufUtil.toRegionInfo(this.mother)).
        setMergedChild(ProtobufUtil.toRegionInfo(this.mergedChild));
    serializer.serialize(msg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    final MasterProcedureProtos.GCRegionStateData msg =
        serializer.deserialize(MasterProcedureProtos.GCRegionStateData.class);
    setRegion(HRegionInfo.convert(msg.getRegionInfo()));
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    final MasterProcedureProtos.GCRegionStateData msg =
        serializer.deserialize(MasterProcedureProtos.GCRegionStateData.class);
    setRegion(ProtobufUtil.toRegionInfo(msg.getRegionInfo()));
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    // Double serialization of regionname. Superclass is also serializing. Fix.
    final MasterProcedureProtos.GCRegionStateData.Builder msg =
        MasterProcedureProtos.GCRegionStateData.newBuilder()
        .setRegionInfo(HRegionInfo.convert(getRegion()));
    serializer.serialize(msg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    // Double serialization of regionname. Superclass is also serializing. Fix.
    final MasterProcedureProtos.GCRegionStateData.Builder msg =
        MasterProcedureProtos.GCRegionStateData.newBuilder()
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegion()));
    serializer.serialize(msg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData mergeTableRegionsMsg =
        serializer.deserialize(MasterProcedureProtos.MergeTableRegionsStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(mergeTableRegionsMsg.getUserInfo()));

    assert(mergeTableRegionsMsg.getRegionInfoCount() == 2);
    regionsToMerge = new HRegionInfo[mergeTableRegionsMsg.getRegionInfoCount()];
    for (int i = 0; i < regionsToMerge.length; i++) {
      regionsToMerge[i] = HRegionInfo.convert(mergeTableRegionsMsg.getRegionInfo(i));
    }

    mergedRegion = HRegionInfo.convert(mergeTableRegionsMsg.getMergedRegionInfo());
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData mergeTableRegionsMsg =
        serializer.deserialize(MasterProcedureProtos.MergeTableRegionsStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(mergeTableRegionsMsg.getUserInfo()));

    assert(mergeTableRegionsMsg.getRegionInfoCount() == 2);
    regionsToMerge = new RegionInfo[mergeTableRegionsMsg.getRegionInfoCount()];
    for (int i = 0; i < regionsToMerge.length; i++) {
      regionsToMerge[i] = ProtobufUtil.toRegionInfo(mergeTableRegionsMsg.getRegionInfo(i));
    }

    mergedRegion = ProtobufUtil.toRegionInfo(mergeTableRegionsMsg.getMergedRegionInfo());
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(HRegionInfo.convert(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(HRegionInfo.convert(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MoveRegionStateData state = serializer.deserialize(MoveRegionStateData.class);
    final HRegionInfo regionInfo = getRegion(); // Get it from super class deserialization.
    final ServerName sourceServer = ProtobufUtil.toServerName(state.getSourceServer());
    final ServerName destinationServer = state.hasDestinationServer() ?
        ProtobufUtil.toServerName(state.getDestinationServer()) : null;
    this.plan = new RegionPlan(regionInfo, sourceServer, destinationServer);
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MoveRegionStateData state = serializer.deserialize(MoveRegionStateData.class);
    final RegionInfo regionInfo = getRegion(); // Get it from super class deserialization.
    final ServerName sourceServer = ProtobufUtil.toServerName(state.getSourceServer());
    final ServerName destinationServer = state.hasDestinationServer() ?
        ProtobufUtil.toServerName(state.getDestinationServer()) : null;
    this.plan = new RegionPlan(regionInfo, sourceServer, destinationServer);
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MasterProcedureProtos.SplitTableRegionStateData splitTableRegionsMsg =
        serializer.deserialize(MasterProcedureProtos.SplitTableRegionStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(splitTableRegionsMsg.getUserInfo()));
    setRegion(HRegionInfo.convert(splitTableRegionsMsg.getParentRegionInfo()));
    assert(splitTableRegionsMsg.getChildRegionInfoCount() == 2);
    daughter_1_HRI = HRegionInfo.convert(splitTableRegionsMsg.getChildRegionInfo(0));
    daughter_2_HRI = HRegionInfo.convert(splitTableRegionsMsg.getChildRegionInfo(1));
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    final MasterProcedureProtos.SplitTableRegionStateData splitTableRegionsMsg =
        serializer.deserialize(MasterProcedureProtos.SplitTableRegionStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(splitTableRegionsMsg.getUserInfo()));
    setRegion(ProtobufUtil.toRegionInfo(splitTableRegionsMsg.getParentRegionInfo()));
    assert(splitTableRegionsMsg.getChildRegionInfoCount() == 2);
    daughter_1_RI = ProtobufUtil.toRegionInfo(splitTableRegionsMsg.getChildRegionInfo(0));
    daughter_2_RI = ProtobufUtil.toRegionInfo(splitTableRegionsMsg.getChildRegionInfo(1));
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.SplitTableRegionStateData.Builder splitTableRegionMsg =
        MasterProcedureProtos.SplitTableRegionStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setParentRegionInfo(HRegionInfo.convert(getRegion()))
        .addChildRegionInfo(HRegionInfo.convert(daughter_1_HRI))
        .addChildRegionInfo(HRegionInfo.convert(daughter_2_HRI));
    serializer.serialize(splitTableRegionMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.SplitTableRegionStateData.Builder splitTableRegionMsg =
        MasterProcedureProtos.SplitTableRegionStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setParentRegionInfo(ProtobufUtil.toRegionInfo(getRegion()))
        .addChildRegionInfo(ProtobufUtil.toRegionInfo(daughter_1_RI))
        .addChildRegionInfo(ProtobufUtil.toRegionInfo(daughter_2_RI));
    serializer.serialize(splitTableRegionMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(HRegionInfo.convert(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(HRegionInfo.convert(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final LockProcedureData state = serializer.deserialize(LockProcedureData.class);
    type = LockType.valueOf(state.getLockType().name());
    description = state.getDescription();
    if (state.getRegionInfoCount() > 0) {
      regionInfos = new HRegionInfo[state.getRegionInfoCount()];
      for (int i = 0; i < state.getRegionInfoCount(); ++i) {
        regionInfos[i] = HRegionInfo.convert(state.getRegionInfo(i));
      }
    } else if (state.hasNamespace()) {
      namespace = state.getNamespace();
    } else if (state.hasTableName()) {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    recoveredMasterLock = state.getIsMasterLock();
    this.lock = setupLock();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final LockProcedureData state = serializer.deserialize(LockProcedureData.class);
    type = LockType.valueOf(state.getLockType().name());
    description = state.getDescription();
    if (state.getRegionInfoCount() > 0) {
      regionInfos = new RegionInfo[state.getRegionInfoCount()];
      for (int i = 0; i < state.getRegionInfoCount(); ++i) {
        regionInfos[i] = ProtobufUtil.toRegionInfo(state.getRegionInfo(i));
      }
    } else if (state.hasNamespace()) {
      namespace = state.getNamespace();
    } else if (state.hasTableName()) {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    recoveredMasterLock = state.getIsMasterLock();
    this.lock = setupLock();
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final LockProcedureData.Builder builder = LockProcedureData.newBuilder()
          .setLockType(LockServiceProtos.LockType.valueOf(type.name()))
          .setDescription(description);
    if (regionInfos != null) {
      for (int i = 0; i < regionInfos.length; ++i) {
        builder.addRegionInfo(HRegionInfo.convert(regionInfos[i]));
      }
    } else if (namespace != null) {
      builder.setNamespace(namespace);
    } else if (tableName != null) {
      builder.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (lockAcquireLatch != null) {
      builder.setIsMasterLock(true);
    }
    serializer.serialize(builder.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final LockProcedureData.Builder builder = LockProcedureData.newBuilder()
          .setLockType(LockServiceProtos.LockType.valueOf(type.name()))
          .setDescription(description);
    if (regionInfos != null) {
      for (int i = 0; i < regionInfos.length; ++i) {
        builder.addRegionInfo(ProtobufUtil.toRegionInfo(regionInfos[i]));
      }
    } else if (namespace != null) {
      builder.setNamespace(namespace);
    } else if (tableName != null) {
      builder.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (lockAcquireLatch != null) {
      builder.setIsMasterLock(true);
    }
    serializer.serialize(builder.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    this.hri = HRegionInfo.convert(serializer.deserialize(HBaseProtos.RegionInfo.class));
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    this.hri = ProtobufUtil.toRegionInfo(serializer.deserialize(HBaseProtos.RegionInfo.class));
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    serializer.serialize(HRegionInfo.convert(getRegion()));
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);
    serializer.serialize(ProtobufUtil.toRegionInfo(getRegion()));
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CloneSnapshotStateData cloneSnapshotMsg =
        serializer.deserialize(MasterProcedureProtos.CloneSnapshotStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(cloneSnapshotMsg.getUserInfo()));
    snapshot = cloneSnapshotMsg.getSnapshot();
    tableDescriptor = ProtobufUtil.toTableDescriptor(cloneSnapshotMsg.getTableSchema());
    if (cloneSnapshotMsg.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(cloneSnapshotMsg.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: cloneSnapshotMsg.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
    if (cloneSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      parentsToChildrenPairMap = new HashMap<>();
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        cloneSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
    // Make sure that the monitor status is set up
    getMonitorStatus();
  }

  /**
   * Action before any real action of cloning from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CloneSnapshotStateData cloneSnapshotMsg =
        serializer.deserialize(MasterProcedureProtos.CloneSnapshotStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(cloneSnapshotMsg.getUserInfo()));
    snapshot = cloneSnapshotMsg.getSnapshot();
    tableDescriptor = ProtobufUtil.toTableDescriptor(cloneSnapshotMsg.getTableSchema());
    if (cloneSnapshotMsg.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(cloneSnapshotMsg.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: cloneSnapshotMsg.getRegionInfoList()) {
        newRegions.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (cloneSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      parentsToChildrenPairMap = new HashMap<>();
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        cloneSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
    // Make sure that the monitor status is set up
    getMonitorStatus();
  }

  /**
   * Action before any real action of cloning from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CloneSnapshotStateData.Builder cloneSnapshotMsg =
      MasterProcedureProtos.CloneSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        cloneSnapshotMsg.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        cloneSnapshotMsg.addParentToChildRegionsPairList(parentToChildrenPair);
      }
    }
    serializer.serialize(cloneSnapshotMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CloneSnapshotStateData.Builder cloneSnapshotMsg =
      MasterProcedureProtos.CloneSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    if (newRegions != null) {
      for (RegionInfo hri: newRegions) {
        cloneSnapshotMsg.addRegionInfo(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        cloneSnapshotMsg.addParentToChildRegionsPairList(parentToChildrenPair);
      }
    }
    serializer.serialize(cloneSnapshotMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.CreateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.CreateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    if (newRegions != null) {
      for (RegionInfo hri: newRegions) {
        state.addRegionInfo(ProtobufUtil.toRegionInfo(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData state =
        serializer.deserialize(MasterProcedureProtos.DeleteTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData state =
        serializer.deserialize(MasterProcedureProtos.DeleteTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
  }

  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (RegionInfo hri: regions) {
        state.addRegionInfo(ProtobufUtil.toRegionInfo(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    MasterProcedureProtos.RecoverMetaStateData state =
        serializer.deserialize(MasterProcedureProtos.RecoverMetaStateData.class);
    this.shouldSplitWal = state.hasShouldSplitWal() && state.getShouldSplitWal();
    this.failedMetaServer = state.hasFailedMetaServer() ?
        ProtobufUtil.toServerName(state.getFailedMetaServer()) : null;
    this.replicaId = state.hasReplicaId() ? state.getReplicaId() : HRegionInfo.DEFAULT_REPLICA_ID;
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);
    MasterProcedureProtos.RecoverMetaStateData state =
        serializer.deserialize(MasterProcedureProtos.RecoverMetaStateData.class);
    this.shouldSplitWal = state.hasShouldSplitWal() && state.getShouldSplitWal();
    this.failedMetaServer = state.hasFailedMetaServer() ?
        ProtobufUtil.toServerName(state.getFailedMetaServer()) : null;
    this.replicaId = state.hasReplicaId() ? state.getReplicaId() : RegionInfo.DEFAULT_REPLICA_ID;
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.RestoreSnapshotStateData restoreSnapshotMsg =
        serializer.deserialize(MasterProcedureProtos.RestoreSnapshotStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(restoreSnapshotMsg.getUserInfo()));
    snapshot = restoreSnapshotMsg.getSnapshot();
    modifiedTableDescriptor =
      ProtobufUtil.toTableDescriptor(restoreSnapshotMsg.getModifiedTableSchema());

    if (restoreSnapshotMsg.getRegionInfoForRestoreCount() == 0) {
      regionsToRestore = null;
    } else {
      regionsToRestore = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRestoreCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRestoreList()) {
        regionsToRestore.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForRemoveCount() == 0) {
      regionsToRemove = null;
    } else {
      regionsToRemove = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRemoveCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRemoveList()) {
        regionsToRemove.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForAddCount() == 0) {
      regionsToAdd = null;
    } else {
      regionsToAdd = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForAddCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForAddList()) {
        regionsToAdd.add(HRegionInfo.convert(hri));
      }
    }
    if (restoreSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        restoreSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
  }

  /**
   * Action before any real action of restoring from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.RestoreSnapshotStateData restoreSnapshotMsg =
        serializer.deserialize(MasterProcedureProtos.RestoreSnapshotStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(restoreSnapshotMsg.getUserInfo()));
    snapshot = restoreSnapshotMsg.getSnapshot();
    modifiedTableDescriptor =
      ProtobufUtil.toTableDescriptor(restoreSnapshotMsg.getModifiedTableSchema());

    if (restoreSnapshotMsg.getRegionInfoForRestoreCount() == 0) {
      regionsToRestore = null;
    } else {
      regionsToRestore = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRestoreCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRestoreList()) {
        regionsToRestore.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForRemoveCount() == 0) {
      regionsToRemove = null;
    } else {
      regionsToRemove = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForRemoveCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForRemoveList()) {
        regionsToRemove.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (restoreSnapshotMsg.getRegionInfoForAddCount() == 0) {
      regionsToAdd = null;
    } else {
      regionsToAdd = new ArrayList<>(restoreSnapshotMsg.getRegionInfoForAddCount());
      for (HBaseProtos.RegionInfo hri: restoreSnapshotMsg.getRegionInfoForAddList()) {
        regionsToAdd.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (restoreSnapshotMsg.getParentToChildRegionsPairListCount() > 0) {
      for (MasterProcedureProtos.RestoreParentToChildRegionsPair parentToChildrenPair:
        restoreSnapshotMsg.getParentToChildRegionsPairListList()) {
        parentsToChildrenPairMap.put(
          parentToChildrenPair.getParentRegionName(),
          new Pair<>(
            parentToChildrenPair.getChild1RegionName(),
            parentToChildrenPair.getChild2RegionName()));
      }
    }
  }

  /**
   * Action before any real action of restoring from snapshot.
   * @param env MasterProcedureEnv
   * @throws IOException
   */
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.RestoreSnapshotStateData.Builder restoreSnapshotMsg =
      MasterProcedureProtos.RestoreSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setModifiedTableSchema(ProtobufUtil.toTableSchema(modifiedTableDescriptor));

    if (regionsToRestore != null) {
      for (HRegionInfo hri: regionsToRestore) {
        restoreSnapshotMsg.addRegionInfoForRestore(HRegionInfo.convert(hri));
      }
    }
    if (regionsToRemove != null) {
      for (HRegionInfo hri: regionsToRemove) {
        restoreSnapshotMsg.addRegionInfoForRemove(HRegionInfo.convert(hri));
      }
    }
    if (regionsToAdd != null) {
      for (HRegionInfo hri: regionsToAdd) {
        restoreSnapshotMsg.addRegionInfoForAdd(HRegionInfo.convert(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        restoreSnapshotMsg.addParentToChildRegionsPairList (parentToChildrenPair);
      }
    }
    serializer.serialize(restoreSnapshotMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.RestoreSnapshotStateData.Builder restoreSnapshotMsg =
      MasterProcedureProtos.RestoreSnapshotStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setSnapshot(this.snapshot)
        .setModifiedTableSchema(ProtobufUtil.toTableSchema(modifiedTableDescriptor));

    if (regionsToRestore != null) {
      for (RegionInfo hri: regionsToRestore) {
        restoreSnapshotMsg.addRegionInfoForRestore(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (regionsToRemove != null) {
      for (RegionInfo hri: regionsToRemove) {
        restoreSnapshotMsg.addRegionInfoForRemove(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (regionsToAdd != null) {
      for (RegionInfo hri: regionsToAdd) {
        restoreSnapshotMsg.addRegionInfoForAdd(ProtobufUtil.toRegionInfo(hri));
      }
    }
    if (!parentsToChildrenPairMap.isEmpty()) {
      final Iterator<Map.Entry<String, Pair<String, String>>> it =
        parentsToChildrenPairMap.entrySet().iterator();
      while (it.hasNext()) {
        final Map.Entry<String, Pair<String, String>> entry = it.next();

        MasterProcedureProtos.RestoreParentToChildRegionsPair.Builder parentToChildrenPair =
          MasterProcedureProtos.RestoreParentToChildRegionsPair.newBuilder()
          .setParentRegionName(entry.getKey())
          .setChild1RegionName(entry.getValue().getFirst())
          .setChild2RegionName(entry.getValue().getSecond());
        restoreSnapshotMsg.addParentToChildRegionsPairList (parentToChildrenPair);
      }
    }
    serializer.serialize(restoreSnapshotMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData state =
        serializer.deserialize(MasterProcedureProtos.ServerCrashStateData.class);
    this.serverName = ProtobufUtil.toServerName(state.getServerName());
    this.carryingMeta = state.hasCarryingMeta()? state.getCarryingMeta(): false;
    // shouldSplitWAL has a default over in pb so this invocation will always work.
    this.shouldSplitWal = state.getShouldSplitWal();
    int size = state.getRegionsOnCrashedServerCount();
    if (size > 0) {
      this.regionsOnCrashedServer = new ArrayList<HRegionInfo>(size);
      for (RegionInfo ri: state.getRegionsOnCrashedServerList()) {
        this.regionsOnCrashedServer.add(HRegionInfo.convert(ri));
      }
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData state =
        serializer.deserialize(MasterProcedureProtos.ServerCrashStateData.class);
    this.serverName = ProtobufUtil.toServerName(state.getServerName());
    this.carryingMeta = state.hasCarryingMeta()? state.getCarryingMeta(): false;
    // shouldSplitWAL has a default over in pb so this invocation will always work.
    this.shouldSplitWal = state.getShouldSplitWal();
    int size = state.getRegionsOnCrashedServerCount();
    if (size > 0) {
      this.regionsOnCrashedServer = new ArrayList<>(size);
      for (org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo ri: state.getRegionsOnCrashedServerList()) {
        this.regionsOnCrashedServer.add(ProtobufUtil.toRegionInfo(ri));
      }
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData.Builder state =
      MasterProcedureProtos.ServerCrashStateData.newBuilder().
      setServerName(ProtobufUtil.toServerName(this.serverName)).
      setCarryingMeta(this.carryingMeta).
      setShouldSplitWal(this.shouldSplitWal);
    if (this.regionsOnCrashedServer != null && !this.regionsOnCrashedServer.isEmpty()) {
      for (HRegionInfo hri: this.regionsOnCrashedServer) {
        state.addRegionsOnCrashedServer(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData.Builder state =
      MasterProcedureProtos.ServerCrashStateData.newBuilder().
      setServerName(ProtobufUtil.toServerName(this.serverName)).
      setCarryingMeta(this.carryingMeta).
      setShouldSplitWal(this.shouldSplitWal);
    if (this.regionsOnCrashedServer != null && !this.regionsOnCrashedServer.isEmpty()) {
      for (RegionInfo hri: this.regionsOnCrashedServer) {
        state.addRegionsOnCrashedServer(ProtobufUtil.toRegionInfo(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.TruncateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.TruncateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    if (state.hasTableSchema()) {
      tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
      tableName = tableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.TruncateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.TruncateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    if (state.hasTableSchema()) {
      tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
      tableName = tableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
  }

  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.TruncateTableStateData.Builder state =
      MasterProcedureProtos.TruncateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setPreserveSplits(preserveSplits);
    if (tableDescriptor != null) {
      state.setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    } else {
      state.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.TruncateTableStateData.Builder state =
      MasterProcedureProtos.TruncateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setPreserveSplits(preserveSplits);
    if (tableDescriptor != null) {
      state.setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    } else {
      state.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (regions != null) {
      for (RegionInfo hri: regions) {
        state.addRegionInfo(ProtobufUtil.toRegionInfo(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
add: 109, delete: 65, change: 1024, unhandled: 7 size_exceptions: 2 size_serialize: 30
-----------2.0.0-alpha4RC0 vs 2.0.0-beta-1-RC0-----------
  private void testSerializeDeserialize(final TableName tableName, final RegionState.State state) {
    RegionState state1 = new RegionState(new HRegionInfo(tableName), state);
    ClusterStatusProtos.RegionState protobuf1 = state1.convert();
    RegionState state2 = RegionState.convert(protobuf1);
    ClusterStatusProtos.RegionState protobuf2 = state1.convert();
    assertEquals("RegionState does not match " + state, state1, state2);
    assertEquals("Protobuf does not match " + state, protobuf1, protobuf2);
+++++++++++++++++++++++
  private void testSerializeDeserialize(final TableName tableName, final RegionState.State state) {
    RegionState state1 = RegionState.createForTesting(new HRegionInfo(tableName), state);
    ClusterStatusProtos.RegionState protobuf1 = state1.convert();
    RegionState state2 = RegionState.convert(protobuf1);
    ClusterStatusProtos.RegionState protobuf2 = state1.convert();
    assertEquals("RegionState does not match " + state, state1, state2);
    assertEquals("Protobuf does not match " + state, protobuf1, protobuf2);
add: 130, delete: 252, change: 1906, unhandled: 7 size_exceptions: 40 size_serialize: 1
-----------2.0.0-beta-1-RC0 vs 2.0.0-beta-1-RC0.2-----------
add: 1, delete: 0, change: 16, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC0.2 vs 2.0.0-beta-1-RC1-----------
add: 1, delete: 0, change: 113, unhandled: 2 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC1 vs 2.0.0-beta-1-RC1.2-----------
add: 0, delete: 0, change: 3, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC1.2 vs 2.0.0-beta-1-RC1.3-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC1.3 vs 2.0.0-beta-1-RC1.4-----------
add: 0, delete: 0, change: 1, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC1.4 vs 2.0.0-beta-1-RC1.5-----------
add: 3, delete: 0, change: 8, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC1.5 vs 2.0.0-beta-1-RC1.6-----------
add: 16, delete: 1, change: 90, unhandled: 1 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC1.6 vs 2.0.0-beta-1-RC1.7-----------
add: 0, delete: 3, change: 18, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.0-beta-1-RC1.7 vs 2.0.0-beta-2RC0.2-----------
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(UnsafeByteOperations.unsafeWrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    toProtobuf().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    serializer.serialize(state.build());
  }

  @Override
add: 73, delete: 13, change: 1492, unhandled: 7 size_exceptions: 12 size_serialize: 3
-----------2.0.0-beta-2RC0.2 vs 2.0.0.1RC0-----------
add: 12, delete: 3, change: 515, unhandled: 4 size_exceptions: 12 size_serialize: 0
-----------2.0.0.1RC0 vs 2.0.0RC0-----------
add: 0, delete: 1, change: 60, unhandled: 1 size_exceptions: 5 size_serialize: 0
-----------2.0.0RC0 vs 2.0.0RC1-----------
add: 1, delete: 0, change: 54, unhandled: 1 size_exceptions: 5 size_serialize: 0
-----------2.0.0RC1 vs 2.0.0RC2-----------
add: 0, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.0RC2 vs 2.0.1RC0-----------
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
add: 30, delete: 2, change: 183, unhandled: 1 size_exceptions: 16 size_serialize: 4
-----------2.0.1RC0 vs 2.0.2RC0-----------
  protected abstract void deserializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The user should override this method if they need a lock on an Entity.
   * A lock can be anything, and it is up to the implementor. The Procedure
   * Framework will call this method just before it invokes {@link #execute(Object)}.
   * It calls {@link #releaseLock(Object)} after the call to execute.
   *
   * <p>If you need to hold the lock for the life of the Procedure -- i.e. you do not
   * want any other Procedure interfering while this Procedure is running, see
   * {@link #holdLock(Object)}.
   *
   * <p>Example: in our Master we can execute request in parallel for different tables.
   * We can create t1 and create t2 and these creates can be executed at the same time.
   * Anything else on t1/t2 is queued waiting that specific table create to happen.
   *
   * <p>There are 3 LockState:
   * <ul><li>LOCK_ACQUIRED should be returned when the proc has the lock and the proc is
   * ready to execute.</li>
   * <li>LOCK_YIELD_WAIT should be returned when the proc has not the lock and the framework
   * should take care of readding the procedure back to the runnable set for retry</li>
   * <li>LOCK_EVENT_WAIT should be returned when the proc has not the lock and someone will
   * take care of readding the procedure back to the runnable set when the lock is available.
   * </li></ul>
   * @return the lock state as described above.
   */
+++++++++++++++++++++++
  protected abstract void deserializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The {@link #doAcquireLock(Object, ProcedureStore)} will be split into two steps, first, it will
   * call us to determine whether we need to wait for initialization, second, it will call
   * {@link #acquireLock(Object)} to actually handle the lock for this procedure.
   * <p/>
   * This is because that when master restarts, we need to restore the lock state for all the
   * procedures to not break the semantic if {@link #holdLock(Object)} is true. But the
   * {@link ProcedureExecutor} will be started before the master finish initialization(as it is part
   * of the initialization!), so we need to split the code into two steps, and when restore, we just
   * restore the lock part and ignore the waitInitialized part. Otherwise there will be dead lock.
   * @return true means we need to wait until the environment has been initialized, otherwise true.
   */
  protected abstract void serializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
+++++++++++++++++++++++
  protected abstract void serializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
add: 23, delete: 6, change: 255, unhandled: 4 size_exceptions: 11 size_serialize: 2
-----------2.0.2RC0 vs 2.0.2RC1-----------
add: 3, delete: 0, change: 9, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.2RC1 vs 2.0.3RC0-----------
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    setOverride(state.getOverride());
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  /**
   * Used by ServerCrashProcedure too skip creating Assigns if not needed.
   * @return Skip out on the assign; returns 'true'/assign if exception.
   */
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    if (isOverride()) {
      state.setOverride(isOverride());
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    // The 'force' flag is the override flag in unassign.
    setOverride(state.getForce());
    this.hostingServer =
        state.hasHostingServer()? ProtobufUtil.toServerName(state.getHostingServer()): null;
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.hostingServer != null) {
      state.setHostingServer(ProtobufUtil.toServerName(this.hostingServer));
    }
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (isOverride()) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
add: 68, delete: 7, change: 189, unhandled: 2 size_exceptions: 8 size_serialize: 4
-----------2.0.3RC0 vs 2.0.4RC0-----------
add: 1, delete: 0, change: 38, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.4RC0 vs 2.0.4RC1-----------
add: 5, delete: 0, change: 74, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------2.0.4RC1 vs 2.0.5RC0-----------
add: 15, delete: 1, change: 176, unhandled: 5 size_exceptions: 4 size_serialize: 0
-----------2.0.5RC0 vs 2.0.5RC1-----------
add: 2, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC1 vs 2.0.5RC2-----------
add: 0, delete: 2, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC2 vs 2.0.5RC3-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC3 vs 2.0.5RC4-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC4 vs 2.0.5RC5-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC5 vs 2.0.5RC6-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC6 vs 2.0.5RC7-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC7 vs 2.0.5RC8-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC8 vs 2.0.5RC9-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC9 vs 2.0.5RC10-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC10 vs 2.0.5RC11-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC11 vs 2.0.5RC12-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC12 vs 2.0.5RC13-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC13 vs 2.0.5RC14-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC14 vs 2.0.5RC15-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.5RC15 vs 2.0.6RC0-----------
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(force);
    for (RegionInfo ri: regionsToMerge) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(ri));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
add: 28, delete: 0, change: 397, unhandled: 2 size_exceptions: 13 size_serialize: 1
-----------2.0.6RC0 vs 2.0.6RC1-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.0.6RC1 vs 2.1.0RC0-----------
  protected abstract void deserializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The {@link #doAcquireLock(Object, ProcedureStore)} will be split into two steps, first, it will
   * call us to determine whether we need to wait for initialization, second, it will call
   * {@link #acquireLock(Object)} to actually handle the lock for this procedure.
   * <p/>
   * This is because that when master restarts, we need to restore the lock state for all the
   * procedures to not break the semantic if {@link #holdLock(Object)} is true. But the
   * {@link ProcedureExecutor} will be started before the master finish initialization(as it is part
   * of the initialization!), so we need to split the code into two steps, and when restore, we just
   * restore the lock part and ignore the waitInitialized part. Otherwise there will be dead lock.
   * @return true means we need to wait until the environment has been initialized, otherwise true.
   */
+++++++++++++++++++++++
  protected abstract void deserializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The user should override this method if they need a lock on an Entity.
   * A lock can be anything, and it is up to the implementor. The Procedure
   * Framework will call this method just before it invokes {@link #execute(Object)}.
   * It calls {@link #releaseLock(Object)} after the call to execute.
   *
   * <p>If you need to hold the lock for the life of the Procedure -- i.e. you do not
   * want any other Procedure interfering while this Procedure is running, see
   * {@link #holdLock(Object)}.
   *
   * <p>Example: in our Master we can execute request in parallel for different tables.
   * We can create t1 and create t2 and these creates can be executed at the same time.
   * Anything else on t1/t2 is queued waiting that specific table create to happen.
   *
   * <p>There are 3 LockState:
   * <ul><li>LOCK_ACQUIRED should be returned when the proc has the lock and the proc is
   * ready to execute.</li>
   * <li>LOCK_YIELD_WAIT should be returned when the proc has not the lock and the framework
   * should take care of readding the procedure back to the runnable set for retry</li>
   * <li>LOCK_EVENT_WAIT should be returned when the proc has not the lock and someone will
   * take care of readding the procedure back to the runnable set when the lock is available.
   * </li></ul>
   * @return the lock state as described above.
   */
  protected abstract void serializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
+++++++++++++++++++++++
  protected abstract void serializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    setOverride(state.getOverride());
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  /**
   * Used by ServerCrashProcedure too skip creating Assigns if not needed.
   * @return Skip out on the assign; returns 'true'/assign if exception.
   */
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    if (isOverride()) {
      state.setOverride(isOverride());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(force);
    for (RegionInfo ri: regionsToMerge) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(ri));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    // The 'force' flag is the override flag in unassign.
    setOverride(state.getForce());
    this.hostingServer =
        state.hasHostingServer()? ProtobufUtil.toServerName(state.getHostingServer()): null;
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.hostingServer != null) {
      state.setHostingServer(ProtobufUtil.toServerName(this.hostingServer));
    }
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (isOverride()) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
add: 74, delete: 162, change: 979, unhandled: 11 size_exceptions: 44 size_serialize: 7
-----------2.1.0RC0 vs 2.1.0RC1-----------
add: 0, delete: 0, change: 23, unhandled: 0 size_exceptions: 2 size_serialize: 0
-----------2.1.0RC1 vs 2.1.1RC0-----------
  protected abstract void deserializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The user should override this method if they need a lock on an Entity.
   * A lock can be anything, and it is up to the implementor. The Procedure
   * Framework will call this method just before it invokes {@link #execute(Object)}.
   * It calls {@link #releaseLock(Object)} after the call to execute.
   *
   * <p>If you need to hold the lock for the life of the Procedure -- i.e. you do not
   * want any other Procedure interfering while this Procedure is running, see
   * {@link #holdLock(Object)}.
   *
   * <p>Example: in our Master we can execute request in parallel for different tables.
   * We can create t1 and create t2 and these creates can be executed at the same time.
   * Anything else on t1/t2 is queued waiting that specific table create to happen.
   *
   * <p>There are 3 LockState:
   * <ul><li>LOCK_ACQUIRED should be returned when the proc has the lock and the proc is
   * ready to execute.</li>
   * <li>LOCK_YIELD_WAIT should be returned when the proc has not the lock and the framework
   * should take care of readding the procedure back to the runnable set for retry</li>
   * <li>LOCK_EVENT_WAIT should be returned when the proc has not the lock and someone will
   * take care of readding the procedure back to the runnable set when the lock is available.
   * </li></ul>
   * @return the lock state as described above.
   */
+++++++++++++++++++++++
  protected abstract void deserializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The {@link #doAcquireLock(Object, ProcedureStore)} will be split into two steps, first, it will
   * call us to determine whether we need to wait for initialization, second, it will call
   * {@link #acquireLock(Object)} to actually handle the lock for this procedure.
   * <p/>
   * This is because that when master restarts, we need to restore the lock state for all the
   * procedures to not break the semantic if {@link #holdLock(Object)} is true. But the
   * {@link ProcedureExecutor} will be started before the master finish initialization(as it is part
   * of the initialization!), so we need to split the code into two steps, and when restore, we just
   * restore the lock part and ignore the waitInitialized part. Otherwise there will be dead lock.
   * @return true means we need to wait until the environment has been initialized, otherwise true.
   */
  protected abstract void serializeStateData(final ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
+++++++++++++++++++++++
  protected abstract void serializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    setOverride(state.getOverride());
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  /**
   * Used by ServerCrashProcedure too skip creating Assigns if not needed.
   * @return Skip out on the assign; returns 'true'/assign if exception.
   */
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    if (isOverride()) {
      state.setOverride(isOverride());
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    // The 'force' flag is the override flag in unassign.
    setOverride(state.getForce());
    this.hostingServer =
        state.hasHostingServer()? ProtobufUtil.toServerName(state.getHostingServer()): null;
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.hostingServer != null) {
      state.setHostingServer(ProtobufUtil.toServerName(this.hostingServer));
    }
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (isOverride()) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
add: 86, delete: 13, change: 298, unhandled: 5 size_exceptions: 9 size_serialize: 6
-----------2.1.1RC0 vs 2.1.2RC0-----------
add: 13, delete: 1, change: 112, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------2.1.2RC0 vs 2.1.2RC1-----------
add: 5, delete: 0, change: 75, unhandled: 0 size_exceptions: 5 size_serialize: 0
-----------2.1.2RC1 vs 2.1.3RC0-----------
add: 15, delete: 1, change: 166, unhandled: 5 size_exceptions: 3 size_serialize: 0
-----------2.1.3RC0 vs 2.1.3RC1-----------
add: 1, delete: 0, change: 10, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.1.3RC1 vs 2.1.4RC0-----------
add: 10, delete: 0, change: 39, unhandled: 2 size_exceptions: 0 size_serialize: 0
-----------2.1.4RC0 vs 2.1.4RC1-----------
add: 3, delete: 0, change: 15, unhandled: 0 size_exceptions: 1 size_serialize: 0
-----------2.1.4RC1 vs 2.1.4RC1.5-----------
add: 0, delete: 0, change: 4, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.1.4RC1.5 vs 2.1.5RC0-----------
add: 5, delete: 1, change: 246, unhandled: 2 size_exceptions: 2 size_serialize: 0
-----------2.1.5RC0 vs 2.1.5RC1-----------
add: 1, delete: 0, change: 7, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.1.5RC1 vs 2.1.6RC0-----------
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(force);
    for (RegionInfo ri: regionsToMerge) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(ri));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
add: 28, delete: 0, change: 260, unhandled: 5 size_exceptions: 20 size_serialize: 1
-----------2.1.6RC0 vs 2.1.6RC1-----------
add: 10, delete: 1, change: 42, unhandled: 1 size_exceptions: 2 size_serialize: 0
-----------2.1.6RC1 vs 2.1.7RC0-----------
add: 80, delete: 0, change: 115, unhandled: 1 size_exceptions: 0 size_serialize: 0
-----------2.1.7RC0 vs 2.1.8RC0-----------
add: 29, delete: 0, change: 171, unhandled: 1 size_exceptions: 0 size_serialize: 0
-----------2.1.8RC0 vs 2.1.9RC0-----------
add: 35, delete: 23, change: 165, unhandled: 1 size_exceptions: 91 size_serialize: 0
-----------2.1.9RC0 vs 2.2.0-RC0-----------
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    setOverride(state.getOverride());
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  /**
   * Used by ServerCrashProcedure too skip creating Assigns if not needed.
   * @return Skip out on the assign; returns 'true'/assign if exception.
   */
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer) throws IOException {
    final AssignRegionStateData state = serializer.deserialize(AssignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    forceNewPlan = state.getForceNewPlan();
    if (state.hasTargetServer()) {
      this.targetServer = ProtobufUtil.toServerName(state.getTargetServer());
    }
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final AssignRegionStateData.Builder state = AssignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    if (isOverride()) {
      state.setOverride(isOverride());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer) throws IOException {
    final AssignRegionStateData.Builder state =
      AssignRegionStateData.newBuilder().setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (forceNewPlan) {
      state.setForceNewPlan(true);
    }
    if (this.targetServer != null) {
      state.setTargetServer(ProtobufUtil.toServerName(this.targetServer));
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(force);
    for (RegionInfo ri: regionsToMerge) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(ri));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    final UnassignRegionStateData state =
        serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    // The 'force' flag is the override flag in unassign.
    setOverride(state.getForce());
    this.hostingServer =
        state.hasHostingServer()? ProtobufUtil.toServerName(state.getHostingServer()): null;
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer) throws IOException {
    final UnassignRegionStateData state = serializer.deserialize(UnassignRegionStateData.class);
    setTransitionState(state.getTransitionState());
    setRegionInfo(ProtobufUtil.toRegionInfo(state.getRegionInfo()));
    this.hostingServer = ProtobufUtil.toServerName(state.getHostingServer());
    force = state.getForce();
    if (state.hasDestinationServer()) {
      this.destinationServer = ProtobufUtil.toServerName(state.getDestinationServer());
    }
    removeAfterUnassigning = state.getRemoveAfterUnassigning();
    if (state.hasAttempt()) {
      setAttempt(state.getAttempt());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    UnassignRegionStateData.Builder state = UnassignRegionStateData.newBuilder()
        .setTransitionState(getTransitionState())
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.hostingServer != null) {
      state.setHostingServer(ProtobufUtil.toServerName(this.hostingServer));
    }
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (isOverride()) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer) throws IOException {
    UnassignRegionStateData.Builder state =
      UnassignRegionStateData.newBuilder().setTransitionState(getTransitionState())
        .setHostingServer(ProtobufUtil.toServerName(this.hostingServer))
        .setRegionInfo(ProtobufUtil.toRegionInfo(getRegionInfo()));
    if (this.destinationServer != null) {
      state.setDestinationServer(ProtobufUtil.toServerName(destinationServer));
    }
    if (force) {
      state.setForce(true);
    }
    if (removeAfterUnassigning) {
      state.setRemoveAfterUnassigning(true);
    }
    if (getAttempt() > 0) {
      state.setAttempt(getAttempt());
    }
    serializer.serialize(state.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
        serializer.deserialize(MasterProcedureProtos.EnableTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
    skipTableStateCheck = enableTableMsg.getSkipTableStateCheck();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer) throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
      serializer.deserialize(MasterProcedureProtos.EnableTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    serializer.serialize(enableTableMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer) throws IOException {
    super.serializeStateData(serializer);

    // the skipTableStateCheck is false so we still need to set it...
    @SuppressWarnings("deprecation")
    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
      MasterProcedureProtos.EnableTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName)).setSkipTableStateCheck(false);

    serializer.serialize(enableTableMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        serializer.deserialize(MasterProcedureProtos.ModifyTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo()));
    modifiedTableDescriptor = ProtobufUtil.toTableDescriptor(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedTableDescriptor =
          ProtobufUtil.toTableDescriptor(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        serializer.deserialize(MasterProcedureProtos.ModifyTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo()));
    modifiedTableDescriptor = ProtobufUtil.toTableDescriptor(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();
    shouldCheckDescriptor = modifyTableMsg.hasShouldCheckDescriptor()
        ? modifyTableMsg.getShouldCheckDescriptor() : false;

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedTableDescriptor =
          ProtobufUtil.toTableDescriptor(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setModifiedTableSchema(ProtobufUtil.toTableSchema(modifiedTableDescriptor))
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify);

    if (unmodifiedTableDescriptor != null) {
      modifyTableMsg
          .setUnmodifiedTableSchema(ProtobufUtil.toTableSchema(unmodifiedTableDescriptor));
    }

    serializer.serialize(modifyTableMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setModifiedTableSchema(ProtobufUtil.toTableSchema(modifiedTableDescriptor))
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify)
            .setShouldCheckDescriptor(shouldCheckDescriptor);

    if (unmodifiedTableDescriptor != null) {
      modifyTableMsg
          .setUnmodifiedTableSchema(ProtobufUtil.toTableSchema(unmodifiedTableDescriptor));
    }

    serializer.serialize(modifyTableMsg.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData state =
        serializer.deserialize(MasterProcedureProtos.ServerCrashStateData.class);
    this.serverName = ProtobufUtil.toServerName(state.getServerName());
    this.carryingMeta = state.hasCarryingMeta()? state.getCarryingMeta(): false;
    // shouldSplitWAL has a default over in pb so this invocation will always work.
    this.shouldSplitWal = state.getShouldSplitWal();
    int size = state.getRegionsOnCrashedServerCount();
    if (size > 0) {
      this.regionsOnCrashedServer = new ArrayList<>(size);
      for (org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo ri: state.getRegionsOnCrashedServerList()) {
        this.regionsOnCrashedServer.add(ProtobufUtil.toRegionInfo(ri));
      }
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ServerCrashStateData state =
        serializer.deserialize(MasterProcedureProtos.ServerCrashStateData.class);
    this.serverName = ProtobufUtil.toServerName(state.getServerName());
    this.carryingMeta = state.hasCarryingMeta()? state.getCarryingMeta(): false;
    // shouldSplitWAL has a default over in pb so this invocation will always work.
    this.shouldSplitWal = state.getShouldSplitWal();
    int size = state.getRegionsOnCrashedServerCount();
    if (size > 0) {
      this.regionsOnCrashedServer = new ArrayList<>(size);
      for (org.apache.hadoop.hbase.shaded.protobuf.generated.HBaseProtos.RegionInfo ri: state.getRegionsOnCrashedServerList()) {
        this.regionsOnCrashedServer.add(ProtobufUtil.toRegionInfo(ri));
      }
    }
    updateProgress(false);
  }

  @Override
add: 117, delete: 191, change: 1178, unhandled: 13 size_exceptions: 132 size_serialize: 10
-----------2.2.0-RC0 vs 2.2.0RC1-----------
  protected void serializeStateData(ProcedureStateSerializer serializer) throws IOException {
    serializer.serialize(
      RegionRemoteProcedureBaseStateData.newBuilder().setRegion(ProtobufUtil.toRegionInfo(region))
        .setTargetServer(ProtobufUtil.toServerName(targetServer)).build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer) throws IOException {
    RegionRemoteProcedureBaseStateData.Builder builder =
      RegionRemoteProcedureBaseStateData.newBuilder().setRegion(ProtobufUtil.toRegionInfo(region))
        .setTargetServer(ProtobufUtil.toServerName(targetServer)).setState(state);
    if (transitionCode != null) {
      builder.setTransitionCode(transitionCode);
      builder.setSeqId(seqId);
    }
    serializer.serialize(builder.build());
  }

  @Override
  protected void deserializeStateData(ProcedureStateSerializer serializer) throws IOException {
    RegionRemoteProcedureBaseStateData data =
      serializer.deserialize(RegionRemoteProcedureBaseStateData.class);
    region = ProtobufUtil.toRegionInfo(data.getRegion());
    targetServer = ProtobufUtil.toServerName(data.getTargetServer());
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer) throws IOException {
    RegionRemoteProcedureBaseStateData data =
      serializer.deserialize(RegionRemoteProcedureBaseStateData.class);
    region = ProtobufUtil.toRegionInfo(data.getRegion());
    targetServer = ProtobufUtil.toServerName(data.getTargetServer());
    state = data.getState();
    if (data.hasTransitionCode()) {
      transitionCode = data.getTransitionCode();
      seqId = data.getSeqId();
    }
  }

  @Override
add: 20, delete: 4, change: 174, unhandled: 5 size_exceptions: 8 size_serialize: 2
-----------2.2.0RC1 vs 2.2.0RC2-----------
add: 3, delete: 0, change: 53, unhandled: 2 size_exceptions: 1 size_serialize: 0
-----------2.2.0RC2 vs 2.2.0RC3-----------
add: 1, delete: 0, change: 116, unhandled: 3 size_exceptions: 0 size_serialize: 0
-----------2.2.0RC3 vs 2.2.0RC4-----------
add: 6, delete: 0, change: 131, unhandled: 6 size_exceptions: 0 size_serialize: 0
-----------2.2.0RC4 vs 2.2.0RC5-----------
add: 11, delete: 0, change: 50, unhandled: 0 size_exceptions: 3 size_serialize: 0
-----------2.2.0RC5 vs 2.2.0RC6-----------
add: 0, delete: 0, change: 9, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.2.0RC6 vs 2.2.1RC0-----------
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(forcible);
    for (int i = 0; i < regionsToMerge.length; ++i) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(regionsToMerge[i]));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    final MasterProcedureProtos.MergeTableRegionsStateData.Builder mergeTableRegionsMsg =
        MasterProcedureProtos.MergeTableRegionsStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setMergedRegionInfo(ProtobufUtil.toRegionInfo(mergedRegion))
        .setForcible(force);
    for (RegionInfo ri: regionsToMerge) {
      mergeTableRegionsMsg.addRegionInfo(ProtobufUtil.toRegionInfo(ri));
    }
    serializer.serialize(mergeTableRegionsMsg.build());
  }

  @Override
add: 28, delete: 0, change: 271, unhandled: 7 size_exceptions: 20 size_serialize: 1
-----------2.2.1RC0 vs 2.2.1RC1-----------
add: 14, delete: 1, change: 98, unhandled: 2 size_exceptions: 2 size_serialize: 0
-----------2.2.1RC1 vs 2.2.1RC2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------2.2.1RC2 vs 2.2.2RC0-----------
add: 84, delete: 2, change: 116, unhandled: 2 size_exceptions: 1 size_serialize: 0
-----------2.2.2RC0 vs 2.2.3RC0-----------
add: 60, delete: 2, change: 309, unhandled: 4 size_exceptions: 47 size_serialize: 0
-----------2.2.3RC0 vs 2.2.3RC1-----------
add: 1, delete: 0, change: 29, unhandled: 1 size_exceptions: 35 size_serialize: 0
-----------2.2.3RC1 vs HBASE-0.90.6-RC3-----------
add: 670, delete: 3957, change: 0, unhandled: 19 size_exceptions: 0 size_serialize: 0
-----------HBASE-0.90.6-RC3 vs HBASE-0.90.6-RC4-----------
add: 0, delete: 0, change: 13, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------HBASE-0.90.6-RC4 vs HBASE-22466-1.5.0RC0-----------
add: 3089, delete: 670, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------HBASE-22466-1.5.0RC0 vs HBASE-22466-1.5.0RC1-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------HBASE-22466-1.5.0RC1 vs HBASE-22466-1.5.0RC2-----------
add: 0, delete: 0, change: 0, unhandled: 0 size_exceptions: 0 size_serialize: 0
-----------HBASE-22466-1.5.0RC2 vs branch-1.2-EOM-----------
add: 52, delete: 392, change: 1246, unhandled: 0 size_exceptions: 56 size_serialize: 0
-----------branch-1.2-EOM vs feature-HBASE-22346-tag-----------
  protected abstract void deserializeStateData(final InputStream stream)
    throws IOException;

  /**
   * The user should override this method, and try to take a lock if necessary.
   * A lock can be anything, and it is up to the implementor.
   * Example: in our Master we can execute request in parallel for different tables
   *          create t1 and create t2 can be executed at the same time.
   *          anything else on t1/t2 is queued waiting that specific table create to happen.
   *
   * @return true if the lock was acquired and false otherwise
   */
+++++++++++++++++++++++
  protected abstract void deserializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * The {@link #doAcquireLock(Object, ProcedureStore)} will be split into two steps, first, it will
   * call us to determine whether we need to wait for initialization, second, it will call
   * {@link #acquireLock(Object)} to actually handle the lock for this procedure.
   * <p/>
   * This is because that when master restarts, we need to restore the lock state for all the
   * procedures to not break the semantic if {@link #holdLock(Object)} is true. But the
   * {@link ProcedureExecutor} will be started before the master finish initialization(as it is part
   * of the initialization!), so we need to split the code into two steps, and when restore, we just
   * restore the lock part and ignore the waitInitialized part. Otherwise there will be dead lock.
   * @return true means we need to wait until the environment has been initialized, otherwise true.
   */
  protected abstract void serializeStateData(final OutputStream stream)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param stream the stream that contains the user serialized data
   */
+++++++++++++++++++++++
  protected abstract void serializeStateData(ProcedureStateSerializer serializer)
    throws IOException;

  /**
   * Called on store load to allow the user to decode the previously serialized
   * state.
   * @param serializer contains the serialized state
   */
  public static RemoteProcedureException deserialize(byte[] bytes)
      throws InvalidProtocolBufferException {
    return fromProto(ForeignExceptionMessage.parseFrom(bytes));
  }

+++++++++++++++++++++++
  public static RemoteProcedureException deserialize(byte[] bytes) throws IOException {
    return fromProto(ForeignExceptionMessage.parseFrom(bytes));
  }

  protected void deserializeStateData(final InputStream stream) throws IOException {
    SequentialProcedureData data = SequentialProcedureData.parseDelimitedFrom(stream);
    executed = data.getExecuted();
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    SequentialProcedureData data = serializer.deserialize(SequentialProcedureData.class);
    executed = data.getExecuted();
  protected void serializeStateData(final OutputStream stream) throws IOException {
    SequentialProcedureData.Builder data = SequentialProcedureData.newBuilder();
    data.setExecuted(executed);
    data.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    SequentialProcedureData.Builder data = SequentialProcedureData.newBuilder();
    data.setExecuted(executed);
    serializer.serialize(data.build());
  }

  @Override
  protected void deserializeStateData(final InputStream stream) throws IOException {
    StateMachineProcedureData data = StateMachineProcedureData.parseDelimitedFrom(stream);
    stateCount = data.getStateCount();
    if (stateCount > 0) {
      states = new int[stateCount];
      for (int i = 0; i < stateCount; ++i) {
        states[i] = data.getState(i);
      }
    } else {
      states = null;
    }
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    StateMachineProcedureData data = serializer.deserialize(StateMachineProcedureData.class);
    stateCount = data.getStateCount();
    if (stateCount > 0) {
      states = new int[stateCount];
      for (int i = 0; i < stateCount; ++i) {
        states[i] = data.getState(i);
      }
      if (isEofState()) {
        stateFlow = Flow.NO_MORE_STATE;
      }
    } else {
      states = null;
    }
  protected void serializeStateData(final OutputStream stream) throws IOException {
    StateMachineProcedureData.Builder data = StateMachineProcedureData.newBuilder();
    for (int i = 0; i < stateCount; ++i) {
      data.addState(states[i]);
    }
    data.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    StateMachineProcedureData.Builder data = StateMachineProcedureData.newBuilder();
    for (int i = 0; i < stateCount; ++i) {
      data.addState(states[i]);
    }
    serializer.serialize(data.build());
  }

  @Override
  public static ForeignException deserialize(byte[] bytes) throws InvalidProtocolBufferException {
    // figure out the data we need to pass
    ForeignExceptionMessage eem = ForeignExceptionMessage.parseFrom(bytes);
    GenericExceptionMessage gem = eem.getGenericException();
    StackTraceElement [] trace = ForeignException.toStackTrace(gem.getTraceList());
    ProxyThrowable dfe = new ProxyThrowable(gem.getMessage(), trace);
    ForeignException e = new ForeignException(eem.getSource(), dfe);
    return e;
  }

  /**
   * Unwind a serialized array of {@link StackTraceElementMessage}s to a
   * {@link StackTraceElement}s.
   * @param traceList list that was serialized
   * @return the deserialized list or <tt>null</tt> if it couldn't be unwound (e.g. wasn't set on
   *         the sender).
   */
+++++++++++++++++++++++
  public static ForeignException deserialize(byte[] bytes)
  throws IOException {
    // figure out the data we need to pass
    ForeignExceptionMessage eem = ForeignExceptionMessage.parseFrom(bytes);
    GenericExceptionMessage gem = eem.getGenericException();
    StackTraceElement [] trace = ForeignException.toStackTrace(gem.getTraceList());
    ProxyThrowable dfe = new ProxyThrowable(gem.getMessage(), trace);
    ForeignException e = new ForeignException(eem.getSource(), dfe);
    return e;
  }

  /**
   * Unwind a serialized array of {@link StackTraceElementMessage}s to a
   * {@link StackTraceElement}s.
   * @param traceList list that was serialized
   * @return the deserialized list or <tt>null</tt> if it couldn't be unwound (e.g. wasn't set on
   *         the sender).
   */
  public static int registerDeserializer(CacheableDeserializer<Cacheable> cd) {
    int idx = identifier.incrementAndGet();
    synchronized (registeredDeserializers) {
      registeredDeserializers.put(idx, cd);
    }
    return idx;
  }

  /**
   * Get the cacheable deserializer as the given identifier Id
   * @param id
   * @return CacheableDeserializer
   */
+++++++++++++++++++++++
  public static int registerDeserializer(CacheableDeserializer<Cacheable> cd) {
    int idx = identifier.incrementAndGet();
    // No synchronization here because keys will be unique
    registeredDeserializers.put(idx, cd);
    return idx;
  }

  /**
   * Get the cacheable deserializer registered at the given identifier Id.
   * @see #registerDeserializer(CacheableDeserializer)
   */
  public static CacheableDeserializer<Cacheable> getDeserializer(int id) {
    return registeredDeserializers.get(id);
+++++++++++++++++++++++
  public static CacheableDeserializer<Cacheable> getDeserializer(int id) {
    return registeredDeserializers.get(id);
  }

  /**
   * Snapshot a map of the current identifiers to class names for reconstruction on reading out
   * of a file.
   */
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    BlockType.TRAILER.readAndCheck(inputStream);

    if (majorVersion > 2
        || (majorVersion == 2 && minorVersion >= HFileReaderV2.PBUF_TRAILER_MINOR_VERSION)) {
      deserializeFromPB(inputStream);
    } else {
      deserializeFromWritable(inputStream);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    int version = inputStream.readInt();
    expectMajorVersion(extractMajorVersion(version));
    expectMinorVersion(extractMinorVersion(version));
  }

  /**
   * Deserialize the file trailer as protobuf
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void deserialize(DataInputStream inputStream) throws IOException {
    HFile.checkFormatVersion(majorVersion);

    BlockType.TRAILER.readAndCheck(inputStream);

    if (majorVersion > 2
        || (majorVersion == 2 && minorVersion >= HFileReaderImpl.PBUF_TRAILER_MINOR_VERSION)) {
      deserializeFromPB(inputStream);
    } else {
      deserializeFromWritable(inputStream);
    }

    // The last 4 bytes of the file encode the major and minor version universally
    int version = inputStream.readInt();
    expectMajorVersion(extractMajorVersion(version));
    expectMinorVersion(extractMinorVersion(version));
  }

  /**
   * Deserialize the file trailer as protobuf
   * @param inputStream
   * @throws IOException
   */
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    HFileProtos.FileTrailerProto.Builder builder = HFileProtos.FileTrailerProto.newBuilder()
      .setFileInfoOffset(fileInfoOffset)
      .setLoadOnOpenDataOffset(loadOnOpenDataOffset)
      .setUncompressedDataIndexSize(uncompressedDataIndexSize)
      .setTotalUncompressedBytes(totalUncompressedBytes)
      .setDataIndexCount(dataIndexCount)
      .setMetaIndexCount(metaIndexCount)
      .setEntryCount(entryCount)
      .setNumDataIndexLevels(numDataIndexLevels)
      .setFirstDataBlockOffset(firstDataBlockOffset)
      .setLastDataBlockOffset(lastDataBlockOffset)
      // TODO this is a classname encoded into an  HFile's trailer. We are going to need to have 
      // some compat code here.
      .setComparatorClassName(comparatorClassName)
      .setCompressionCodec(compressionCodec.ordinal());
    if (encryptionKey != null) {
      builder.setEncryptionKey(ByteStringer.wrap(encryptionKey));
    }
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    builder.build().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
+++++++++++++++++++++++
  void serializeAsPB(DataOutputStream output) throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    // We need this extra copy unfortunately to determine the final size of the
    // delimited output, see use of baos.size() below.
    toProtobuf().writeDelimitedTo(baos);
    baos.writeTo(output);
    // Pad to make up the difference between variable PB encoding length and the
    // length when encoded as writable under earlier V2 formats. Failure to pad
    // properly or if the PB encoding is too big would mean the trailer wont be read
    // in properly by HFile.
    int padding = getTrailerSize() - NOT_PB_SIZE - baos.size();
    if (padding < 0) {
      throw new IOException("Pbuf encoding size exceeded fixed trailer size limit");
    }
    for (int i = 0; i < padding; i++) {
      output.write(0);
    }
  }

  /**
   * Deserialize the fixed file trailer from the given stream. The version needs
   * to already be specified. Make sure this is consistent with
   * {@link #serialize(DataOutputStream)}.
   *
   * @param inputStream
   * @throws IOException
   */
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData state =
      MasterProcedureProtos.CreateTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
    hTableDescriptor = HTableDescriptor.convert(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<HRegionInfo>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(HRegionInfo.convert(hri));
      }
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.CreateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
    if (state.getRegionInfoCount() == 0) {
      newRegions = null;
    } else {
      newRegions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        newRegions.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
        .setTableSchema(hTableDescriptor.convert());
    if (newRegions != null) {
      for (HRegionInfo hri: newRegions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.CreateTableStateData.Builder state =
      MasterProcedureProtos.CreateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableSchema(ProtobufUtil.toTableSchema(tableDescriptor));
    if (newRegions != null) {
      for (RegionInfo hri: newRegions) {
        state.addRegionInfo(ProtobufUtil.toRegionInfo(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData state =
      MasterProcedureProtos.DeleteTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<HRegionInfo>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData state =
        serializer.deserialize(MasterProcedureProtos.DeleteTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    tableName = ProtobufUtil.toTableName(state.getTableName());
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
  }

  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.convert(hri));
      }
    }
    state.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DeleteTableStateData.Builder state =
      MasterProcedureProtos.DeleteTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName));
    if (regions != null) {
      for (RegionInfo hri: regions) {
        state.addRegionInfo(ProtobufUtil.toRegionInfo(hri));
      }
    }
    serializer.serialize(state.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(disableTableMsg.getUserInfo());
    tableName = ProtobufUtil.toTableName(disableTableMsg.getTableName());
    skipTableStateCheck = disableTableMsg.getSkipTableStateCheck();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.DisableTableStateData disableTableMsg =
        serializer.deserialize(MasterProcedureProtos.DisableTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(disableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(disableTableMsg.getTableName());
    skipTableStateCheck = disableTableMsg.getSkipTableStateCheck();
  }

  // For disabling a table, we does not care whether a region can be online so hold the table xlock
  // for ever. This will simplify the logic as we will not be conflict with procedures other than
  // SCP.
  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.DisableTableStateData.Builder disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    disableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.DisableTableStateData.Builder disableTableMsg =
        MasterProcedureProtos.DisableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    serializer.serialize(disableTableMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo());
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
    skipTableStateCheck = enableTableMsg.getSkipTableStateCheck();
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer) throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.EnableTableStateData enableTableMsg =
      serializer.deserialize(MasterProcedureProtos.EnableTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(enableTableMsg.getUserInfo()));
    tableName = ProtobufUtil.toTableName(enableTableMsg.getTableName());
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
        MasterProcedureProtos.EnableTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setTableName(ProtobufUtil.toProtoTableName(tableName))
            .setSkipTableStateCheck(skipTableStateCheck);

    enableTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer) throws IOException {
    super.serializeStateData(serializer);

    // the skipTableStateCheck is false so we still need to set it...
    @SuppressWarnings("deprecation")
    MasterProcedureProtos.EnableTableStateData.Builder enableTableMsg =
      MasterProcedureProtos.EnableTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
        .setTableName(ProtobufUtil.toProtoTableName(tableName)).setSkipTableStateCheck(false);

    serializer.serialize(enableTableMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo());
    modifiedHTableDescriptor = HTableDescriptor.convert(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedHTableDescriptor =
          HTableDescriptor.convert(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData modifyTableMsg =
        serializer.deserialize(MasterProcedureProtos.ModifyTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(modifyTableMsg.getUserInfo()));
    modifiedTableDescriptor = ProtobufUtil.toTableDescriptor(modifyTableMsg.getModifiedTableSchema());
    deleteColumnFamilyInModify = modifyTableMsg.getDeleteColumnFamilyInModify();
    shouldCheckDescriptor = modifyTableMsg.hasShouldCheckDescriptor()
        ? modifyTableMsg.getShouldCheckDescriptor() : false;

    if (modifyTableMsg.hasUnmodifiedTableSchema()) {
      unmodifiedTableDescriptor =
          ProtobufUtil.toTableDescriptor(modifyTableMsg.getUnmodifiedTableSchema());
    }
  }

  @Override
  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(user))
            .setModifiedTableSchema(modifiedHTableDescriptor.convert())
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify);

    if (unmodifiedHTableDescriptor != null) {
      modifyTableMsg.setUnmodifiedTableSchema(unmodifiedHTableDescriptor.convert());
    }

    modifyTableMsg.build().writeDelimitedTo(stream);
  }

  @Override
+++++++++++++++++++++++
  protected void serializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.serializeStateData(serializer);

    MasterProcedureProtos.ModifyTableStateData.Builder modifyTableMsg =
        MasterProcedureProtos.ModifyTableStateData.newBuilder()
            .setUserInfo(MasterProcedureUtil.toProtoUserInfo(getUser()))
            .setModifiedTableSchema(ProtobufUtil.toTableSchema(modifiedTableDescriptor))
            .setDeleteColumnFamilyInModify(deleteColumnFamilyInModify)
            .setShouldCheckDescriptor(shouldCheckDescriptor);

    if (unmodifiedTableDescriptor != null) {
      modifyTableMsg
          .setUnmodifiedTableSchema(ProtobufUtil.toTableSchema(unmodifiedTableDescriptor));
    }

    serializer.serialize(modifyTableMsg.build());
  }

  @Override
  public void deserializeStateData(final InputStream stream) throws IOException {
    super.deserializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData state =
      MasterProcedureProtos.TruncateTableStateData.parseDelimitedFrom(stream);
    user = MasterProcedureUtil.toUserInfo(state.getUserInfo());
    if (state.hasTableSchema()) {
      hTableDescriptor = HTableDescriptor.convert(state.getTableSchema());
      tableName = hTableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<HRegionInfo>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(HRegionInfo.convert(hri));
      }
    }
  }

+++++++++++++++++++++++
  protected void deserializeStateData(ProcedureStateSerializer serializer)
      throws IOException {
    super.deserializeStateData(serializer);

    MasterProcedureProtos.TruncateTableStateData state =
        serializer.deserialize(MasterProcedureProtos.TruncateTableStateData.class);
    setUser(MasterProcedureUtil.toUserInfo(state.getUserInfo()));
    if (state.hasTableSchema()) {
      tableDescriptor = ProtobufUtil.toTableDescriptor(state.getTableSchema());
      tableName = tableDescriptor.getTableName();
    } else {
      tableName = ProtobufUtil.toTableName(state.getTableName());
    }
    preserveSplits = state.getPreserveSplits();
    if (state.getRegionInfoCount() == 0) {
      regions = null;
    } else {
      regions = new ArrayList<>(state.getRegionInfoCount());
      for (HBaseProtos.RegionInfo hri: state.getRegionInfoList()) {
        regions.add(ProtobufUtil.toRegionInfo(hri));
      }
    }
  }

  public void serializeStateData(final OutputStream stream) throws IOException {
    super.serializeStateData(stream);

    MasterProcedureProtos.TruncateTableStateData.Builder state =
      MasterProcedureProtos.TruncateTableStateData.newBuilder()
        .setUserInfo(MasterProcedureUtil.toProtoUserInfo(this.user))
        .setPreserveSplits(preserveSplits);
    if (hTableDescriptor != null) {
      state.setTableSchema(hTableDescriptor.convert());
    } else {
      state.setTableName(ProtobufUtil.toProtoTableName(tableName));
    }
    if (regions != null) {
      for (HRegionInfo hri: regions) {
        state.addRegionInfo(HRegionInfo.conve